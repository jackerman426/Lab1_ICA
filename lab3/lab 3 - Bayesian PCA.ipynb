{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lab 3: Bayesian PCA\n",
      "\n",
      "### Machine Learning: Principles and Methods, November 2013\n",
      "\n",
      "* The lab exercises should be made in groups of three people, or at least two people.\n",
      "* The deadline is Friday, 13 December, 23:59.\n",
      "* Assignment should be sent to T.S.Cohen at uva dot nl (Taco Cohen). The subject line of your email should be \"[MLPM2013] lab#_lastname1\\_lastname2\\_lastname3\". \n",
      "* Put your and your teammates' names in the body of the email\n",
      "* Attach the .IPYNB (IPython Notebook) file containing your code and answers. Naming of the file follows the same rule as the subject line. For example, if the subject line is \"[MLPM2013] lab01\\_Kingma\\_Hu\", the attached file should be \"lab01\\_Kingma\\_Hu.ipynb\". Only use underscores (\"\\_\") to connect names, otherwise the files cannot be parsed.\n",
      "\n",
      "Notes on implementation:\n",
      "\n",
      "* You should write your code and answers in an IPython Notebook: http://ipython.org/notebook.html. If you have problems, please contact us.\n",
      "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
      "* NOTE: test your code and make sure we can run your notebook / scripts!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Tzakris Marios sn: 10406875, Methenitis sn: 10407537"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Introduction\n",
      "\n",
      "In this lab assignment, we will implement a variational algorithm for Bayesian PCA. Unlike regular PCA based on maximization of retained variance or minimization of projection error (see Bishop, 12.1.1 and 12.1.2), probabilistic PCA defines a proper density model over observed and latent variables. We will work with a fully Bayesian model this time, which is to say that we will put priors on our parameters and will be interested in learning the posterior over those parameters. Bayesian methods are very elegant, but require a shift in mindset: we are no longer looking for a point estimate of the parameters (as in maximum likelihood or MAP), but for a full posterior distribution.\n",
      "\n",
      "The integrals involved in a Bayesian analysis are usually analytically intractable, so that we must resort to approximations. In this lab assignment, we will implement the variational method described in Bishop99. Chapters 10 and 12 of the PRML book contain additional material that may be useful when doing this exercise.\n",
      "\n",
      "* [Bishop99] Variational Principal Components, C. Bishop, ICANN 1999 - http://research.microsoft.com/pubs/67241/bishop-vpca-icann-99.pdf\n",
      "\n",
      "Below, you will find some code to get you started."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import scipy.special as sp\n",
      "import numpy as np\n",
      "import pylab as P\n",
      "import sys\n",
      "import cPickle, gzip\n",
      "\n",
      "DEBUG = 0\n",
      "\n",
      "class BayesianPCA(object):\n",
      "    \n",
      "    def __init__(self, d, N, a_alpha=10e-3, b_alpha=10e-3, a_tau=10e-3, b_tau=10e-3, beta=10e-3):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        self.d = d # number of dimensions\n",
      "        self.N = N # number of data points        \n",
      "        # Hyperparameters\n",
      "        self.a_alpha = a_alpha\n",
      "        self.b_alpha = b_alpha\n",
      "        self.a_tau = a_tau\n",
      "        self.b_tau = b_tau\n",
      "        self.beta = beta\n",
      "\n",
      "        # Variational parameters\n",
      "        self.means_z = np.random.randn(d, N) # called x in bishop99\n",
      "        self.sigma_z = np.random.randn(d, d)\n",
      "        self.mean_mu = np.random.randn(d, 1)\n",
      "        self.sigma_mu = np.random.randn(d, d)\n",
      "        self.means_w = np.random.randn(d, d)\n",
      "        self.sigma_w = np.random.randn(d, d)\n",
      "        self.a_alpha_tilde = np.abs(np.random.randn(1))\n",
      "        self.bs_alpha_tilde = np.abs(np.random.randn(d, 1))\n",
      "        self.a_tau_tilde = np.abs(np.random.randn(1))\n",
      "        self.b_tau_tilde = np.abs(np.random.randn(1))\n",
      "        # initialize latent variable z\n",
      "        self.data = np.random.randn(d, N)\n",
      "        # expectation of tau\n",
      "        self.exp_tau = self.a_tau_tilde / self.b_tau_tilde\n",
      "\n",
      "    def __checkSizes(self):\n",
      "        if(self.means_z.shape != (self.d, self.N)):\n",
      "            print \"ERROR self.means_z.shape\"\n",
      "            sys.exit()\n",
      "        if(self.sigma_z.shape != (self.d, self.d)):\n",
      "            print \"ERROR self.sigma_z\"\n",
      "            sys.exit()\n",
      "        if(self.mean_mu.shape != (self.d, 1)):\n",
      "            print \"ERROR self.mean_mu\"\n",
      "            sys.exit()\n",
      "        if(self.sigma_mu.shape != (self.d, self.d)):\n",
      "            print \"ERROR elf.sigma_mu\"\n",
      "            sys.exit()\n",
      "        if(self.means_w.shape != (self.d, self.d)):\n",
      "            print \"ERROR self.means_w\"\n",
      "            sys.exit()\n",
      "        if(self.sigma_w.shape != (self.d, self.d)):\n",
      "            print \"ERROR self.sigma_w\"\n",
      "            sys.exit()\n",
      "        if(self.bs_alpha_tilde.shape != (self.d, 1)):\n",
      "            print \"ERROR self.bs_alpha_tilde\"\n",
      "            sys.exit()\n",
      "    \n",
      "    def __update_z(self, X):\n",
      "        \"\"\"\n",
      "        Q(Z) = prod_n N(z_n|m_z,sigma_z)\n",
      "            where m_z = <tau>*sigma_z|<tau>*<W^T>*(x_n-<mu>)\n",
      "                  sigma_x = (I+<tau>*<W^T*W>)^-1\n",
      "\n",
      "        \"\"\"    \n",
      "        #update sigma_z\n",
      "        self.sigma_z = np.linalg.inv(np.identity(self.d) + np.multiply(self.exp_tau, np.trace(self.sigma_w) + np.dot(self.means_w.T, self.means_w)))\n",
      "        # update mean_z\n",
      "        self.means_z = self.exp_tau*np.dot(np.dot(self.sigma_z, self.means_w.T) , (X - self.mean_mu))\n",
      "        if DEBUG:\n",
      "            print \"============= UPDATE_Z ==============\"\n",
      "            print \"self.means_z\\n\", self.means_z\n",
      "            print \"self.sigma_z\\n\", self.sigma_z\n",
      "    \n",
      "    def __update_mu(self, X):\n",
      "        \"\"\"\n",
      "        Q(mu) = N(mu|m_mu,sigma_mu)\n",
      "            where m_mu = <tau>*sigma_mu*sum_n(x_n-<W><z_n>)\n",
      "                  sigma_mu = (beta+N<tau>)^-1 * I\n",
      "        \"\"\"\n",
      "        #update sigma_mu\n",
      "        self.sigma_mu = (self.beta + self.N * self.exp_tau)**(-1) * np.identity(self.d)\n",
      "        #update mean_mu\n",
      "        self.mean_mu = self.exp_tau * np.dot(self.sigma_mu,np.sum(X - np.dot(self.means_w, self.means_z), axis=1)).reshape((self.d,1))\n",
      "\n",
      "        if DEBUG:\n",
      "            print \"============= UPDATE_MU ==============\"\n",
      "            print \"self.sigma_mu\\n\", self.sigma_mu\n",
      "            print \"self.sigma_mu\\n\", self.mean_mu\n",
      "    \n",
      "    def __update_w(self, X):\n",
      "        # sigma of w\n",
      "        a_diag = np.diagflat(self.a_alpha_tilde/self.bs_alpha_tilde)\n",
      "        sum_ = np.zeros((self.d, self.d))\n",
      "        for n in xrange(self.N):\n",
      "            sum_ += self.sigma_z + np.dot(self.means_z[:,n].reshape((self.d,1)), self.means_z[:,n].T.reshape((1,self.d)))\n",
      "        self.sigma_w = np.linalg.inv(a_diag + self.exp_tau * sum_)\n",
      "        # means of w\n",
      "        self_means_w = np.dot(self.exp_tau*self.sigma_w, np.dot(self.means_z, (X - self.mean_mu).T)).T\n",
      "        # debug prints\n",
      "        if DEBUG:\n",
      "            print \"============= UPDATE_W ==============\"\n",
      "            print \"self.sigma_w\\n\", self.sigma_w\n",
      "            print \"self.means_w\\n\", self.means_w\n",
      "\n",
      "    \n",
      "    def __update_alpha(self):\n",
      "        # a_alpha_tilted\n",
      "        self.a_alpha_tilde = self.a_alpha + self.d / 2\n",
      "        # bs_alpha_tilde\n",
      "        for i in xrange(self.d):\n",
      "            self.bs_alpha_tilde[i] = self.b_alpha + np.dot(self.means_w[i], self.means_w.T[i])/2\n",
      "        # debug prints\n",
      "        if DEBUG:\n",
      "            print \"============= UPDATE_alpha ==============\"\n",
      "            print \"self.a_alpha_tilde\\n\", self.a_alpha_tilde\n",
      "            print \"self.bs_alpha_tilde\\n\", self.bs_alpha_tilde\n",
      "\n",
      "    def __update_tau(self, X):\n",
      "        # update a_tau_tilde\n",
      "        self.a_tau_tilde = self.a_tau + (self.N * self.d) / 2\n",
      "        sum_ = 0\n",
      "        # update b_tau_tilde\n",
      "        for n in xrange(self.N):\n",
      "            sum_ += np.dot(X.T[n] , X.T[n]) + np.dot(self.means_z.T[n], self.means_z.T[n])\n",
      "            + np.trace((self.means_w.T*self.means_w) * (self.sigma_z + np.dot(self.means_z, self.means_z.T)))\n",
      "            + 2 * np.dot(np.dot(self.mean_mu.T, self.means_w), self.means_z.T[n])\n",
      "            -2 * np.dot(X.T[n], self.mean_mu)\n",
      "            -2 * np.dot(np.dot(X.T[n], self.means_w), self.means_z[:,n])\n",
      "        self.b_tau_tilde = self.b_tau + sum_ / 2\n",
      "        # debug prints\n",
      "        if DEBUG:\n",
      "            print \"============= UPDATE_tau ==============\"\n",
      "            print \"self.bs_alpha_tilde\\n\", self.a_tau_tilde\n",
      "            print \"self.b_tau_tilde\\n\", self.b_tau_tilde\n",
      "\n",
      "    def L(self, X):\n",
      "        L = 0.0\n",
      "        # E[ln P(Z)]\n",
      "        exp_ln_pz = -(self.N / 2)*np.trace(self.sigma_z)\n",
      "        for n in xrange(self.N):\n",
      "            exp_ln_pz += -(1/2)*np.dot(self.means_z[:,n].T,self.means_z[:,n])\n",
      "        \n",
      "        #E[ln P(W|a)]\n",
      "        exp_ln_pwa = 0\n",
      "        for i in xrange(self.d):\n",
      "            exp_ln_pwa += (-self.d /2) * (sp.psi(self.a_alpha_tilde)-np.log(self.bs_alpha_tilde[i][0]))- 1/2 * (np.trace(self.sigma_w) + np.dot(self.means_w[i].T, self.means_w[i]))\n",
      "\n",
      "\n",
      "        #E[lnP(a)]\n",
      "        exp_ln_pa = 0\n",
      "        for i in xrange(self.d):\n",
      "            exp_ln_pa += (self.a_alpha - 1) * (sp.psi(self.a_alpha_tilde) - np.log(self.bs_alpha_tilde[i][0])) - self.b_alpha * (self.a_alpha_tilde / self.bs_alpha_tilde[i][0])\n",
      "\n",
      "        #E[lnP(mu)]\n",
      "        exp_ln_pmu = -(self.beta / 2) * (np.trace(self.sigma_mu) + np.dot(self.mean_mu,self.mean_mu.T)[0][0])\n",
      "        \n",
      "        #E[lnP(tau)]\n",
      "        exp_ln_ptau = (sp.psi(self.a_tau_tilde) - np.log(self.b_tau_tilde)) - (self.a_tau_tilde / self.b_tau_tilde)\n",
      "\n",
      "        #E(lnQ(alpha))\n",
      "        exp_ln_qa_temp = 0\n",
      "        for i in xrange(self.d):\n",
      "            exp_ln_qa_temp +=  (sp.psi(self.a_alpha_tilde) - np.log(self.bs_alpha_tilde[i][0]))\n",
      "        exp_ln_qa = (self.a_alpha_tilde - 1) * (exp_ln_qa_temp) - self.d*self.a_alpha_tilde\n",
      "\n",
      "        #E(lnQ(\\tau))\n",
      "        exp_ln_qt =  (self.a_tau_tilde - 1) * (sp.psi(self.a_tau_tilde) - np.log(self.b_tau_tilde)) - self.a_tau_tilde\n",
      "\n",
      "\n",
      "        L = exp_ln_pz + exp_ln_pwa + exp_ln_pa + exp_ln_pmu + exp_ln_ptau + exp_ln_qa + exp_ln_qt\n",
      "        return L\n",
      "\n",
      "    def CheckFittedModel(self, X):\n",
      "        print \"Checking if the model is well fitted...\"\n",
      "        print \"Matrices must be identical:\"\n",
      "        print X\n",
      "        print np.dot(self.means_w,self.means_z) + self.mean_mu\n",
      "    \n",
      "    def fit(self, X, iterations):\n",
      "        print \"fitting the model...\"\n",
      "        for x in xrange(iterations):\n",
      "            if (x%(iterations/10.0)==0.0):\n",
      "                print \".\",\n",
      "            vPca.__checkSizes()\n",
      "            self.__update_z(X)\n",
      "            self.__update_mu(X)\n",
      "            self.__update_w(X)\n",
      "            self.__update_alpha()\n",
      "            self.__update_tau(X)\n",
      "        print \"\\n\",iterations, \"iterations done\"\n",
      "        \n",
      "    def _blob(self,x,y,area,colour):\n",
      "        \"\"\"\n",
      "        Draws a square-shaped blob with the given area (< 1) at\n",
      "        the given coordinates.\n",
      "        Source: http://wiki.scipy.org/Cookbook/Matplotlib/HintonDiagrams\n",
      "        \"\"\"\n",
      "        hs = np.sqrt(area) / 2\n",
      "        xcorners = np.array([x - hs, x + hs, x + hs, x - hs])\n",
      "        ycorners = np.array([y - hs, y - hs, y + hs, y + hs])\n",
      "        P.fill(xcorners, ycorners, colour, edgecolor=colour)\n",
      "\n",
      "    def hinton(self, maxWeight=None):\n",
      "        \"\"\"\n",
      "        Draws a Hinton diagram for visualizing a weight matrix. \n",
      "        Temporarily disables matplotlib interactive mode if it is on, \n",
      "        otherwise this takes forever.\n",
      "        Source: http://wiki.scipy.org/Cookbook/Matplotlib/HintonDiagrams\n",
      "        \"\"\"\n",
      "        reenable = False\n",
      "        if P.isinteractive():\n",
      "            P.ioff()\n",
      "        P.clf()\n",
      "        height, width = self.means_w.shape\n",
      "        if not maxWeight:\n",
      "            maxWeight = 2**np.ceil(np.log(np.max(np.abs(self.means_w)))/np.log(2))\n",
      "\n",
      "        P.fill(np.array([0,width,width,0]),np.array([0,0,height,height]),'gray')\n",
      "        P.axis('off')\n",
      "        P.axis('equal')\n",
      "        for x in xrange(width):\n",
      "            for y in xrange(height):\n",
      "                _x = x+1\n",
      "                _y = y+1\n",
      "                w = self.sigma_w[y,x]\n",
      "                if w > 0:\n",
      "                    self._blob(_x - 0.5, height - _y + 0.5, min(1,w/maxWeight),'white')\n",
      "                elif w < 0:\n",
      "                    self._blob(_x - 0.5, height - _y + 0.5, min(1,-w/maxWeight),'black')\n",
      "        if reenable:\n",
      "            P.ion()\n",
      "        P.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['mean', 'cov']\n",
        "`%pylab --no-import-all` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.random.randn(4,2)\n",
      "vPca = BayesianPCA(4,2)\n",
      "vPca.fit(X, 10000)\n",
      "vPca.CheckFittedModel(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fitting the model...\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000 iterations done\n",
        "Checking if the model is well fitted...\n",
        "Matrices must be identical:\n",
        "[[ 1.07809398 -0.76502539]\n",
        " [ 0.16746021  1.22672416]\n",
        " [-0.9812436  -0.27159042]\n",
        " [ 0.60408421  1.55427696]]\n",
        "[[ 0.84114933 -0.53312396]\n",
        " [ 0.2974436   1.07785104]\n",
        " [-0.5985833  -0.63741058]\n",
        " [ 0.83909822  1.28992475]]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. The Q-distribution (5 points)\n",
      "\n",
      "In variational Bayes, we introduce a distribution $Q(\\Theta)$ over parameters / latent variables in order to make inference tractable. We can think of $Q$ as being an approximation of a certain distribution. What function does $Q$ approximate, $p(D|\\Theta)$, $p(\\Theta|D)$, $p(D, \\Theta)$, $p(\\Theta)$, or $p(D)$, and how do you see that from the equation $\\ln p(D) = \\mathcal{L}(Q) + \\mathrm{KL}(Q||P)$?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$Q$ approximates $p(\u03b8|D)$. In an ideal situation where the lower bound $L(Q)$ would be equal to the true log marginal likelihood $\\ln P(D)$, the $KL(Q||P)$ must be $0$. By taking the definition of $KL(Q||P)$ (eq.11) : $KL(Q||P) = - \\int Q(\\theta) \\ln \\frac{P(\\theta|D)}{Q(\\theta)} \\mathrm{d}\\theta$. We can see that $P(\u03b8|D)$ must be equal to $Q(\u0398)$ for $KL(Q||P)$ to be equal to zero. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. The mean-field approximation (15 points)\n",
      "\n",
      "Equation 13 from [Bishop99] is a very powerful result: assuming only that $Q(\\Theta)$ factorizes in a certain way (no assumptions on the functional form of the factors $Q_i$!), we get a set of coupled equations for the $Q_i$.\n",
      "\n",
      "However, the expression given in eq. 13 for Q_i contains a small mistake. Starting with the expression for the lower bound $\\mathcal{L}(Q)$, derive the correct expression (and include your derivation). You can proceed as follows: first, substitute the factorization of $Q$ (eq. 12) into the definition of $\\mathcal{L}(Q)$ and separate $\\mathcal{L}(Q)$ into $Q_i$-dependent and $Q_i$-independent terms. At this point, you should be able to spot the expectations $\\langle\\cdot\\rangle_{k \\neq i}$ over the other $Q$-distributions that appear in Bishop's solution (eq. 13). Now, keeping all $Q_k, k \\neq i$ fixed, maximize the expression with respect to $Q_i$. You should be able to spot the form of the optimal $ln Q_i$, from which $Q_i$ can easily be obtained."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Answer\n",
      "\n",
      "Starting from equation (10) we have:\n",
      "\n",
      "$L(Q) = \\int Q(\\theta) \\ln \\cfrac{P(D,\\theta)}{Q(\\theta)}$, replacing $Q(\\theta)$, with $\\prod_i Q_i(\\theta_i)$, we are going to have:\n",
      "\\begin{align*}\n",
      "L(Q) &= \\int \\prod_i Q_i(\\theta_i) \\ln \\cfrac{P(D,\\theta)}{\\prod_i Q_i(\\theta_i)} \\mathrm{d}\\theta\\\\\n",
      "&= \\int \\prod_i Q_i(\\theta_i) ( \\ln P(D,\\theta) - \\ln \\prod_i Q_i(\\theta_i)) \\mathrm{d}\\theta\\\\\n",
      "&= \\int \\prod_i Q_i(\\theta_i) \\ln P(D,\\theta) \\mathrm{d}\\theta - \\int \\prod_i Q_i(\\theta_i) \\ln \\prod_i Q_i(\\theta_i) \\mathrm{d}\\theta\\\\\n",
      "&= \\int \\prod_i Q_i(\\theta_i) \\ln P(D,\\theta) \\mathrm{d}\\theta - \\int \\prod_i Q_i(\\theta_i) \\sum_i \\ln Q_i(\\theta_i) \\mathrm{d}\\theta\\\\\n",
      "&= \\int Q_j(\\theta_j) \\prod_{i \\neq j} Q_i(\\theta_i) \\ln P(D,\\theta) \\mathrm{d}\\theta - \\int Q_j(\\theta_j) \\prod_{i \\neq j} Q_i(\\theta_i) \\sum_i \\ln Q_j(\\theta_j) \\prod_{i \\neq j} Q_i(\\theta_i) \\mathrm{d}\\theta$ (1)\\\\\n",
      "&= \\int Q_j(\\theta_j) \\int \\left( \\prod_{i \\neq j} Q_i(\\theta_i) \\ln P(D,\\theta) \\right) \\mathrm{d}\\theta_i \\mathrm{d}\\theta_j - \\int Q_j(\\theta_j) \\ln Q_j(\\theta_j) \\mathrm{d}\\theta_j + const (2)\n",
      "\\end{align*}\n",
      ", where we define a distribution as in 10.7(Bishop book) $\\bar{P}(D,\\theta)$ so, $\\ln \\bar{P}(D,\\theta) = \\langle \\ln P(D,\\theta) \\rangle_{i \\neq j} + c$, where c constant.\n",
      "\n",
      "Now, we can write the first them of the equation (1) as:\n",
      "\n",
      "\\begin{equation}\n",
      "\\int \\prod_{i \\neq j} Q_i(\\theta_i) \\ln P(D,\\theta) \\mathrm{d}\\theta_i =  \\langle \\ln P(D,\\theta) \\rangle_{i \\neq j}\n",
      "\\end{equation}\n",
      "\n",
      "If we now transform (2) in this way knowing that $\\int c \\ln(a) - \\int c \\ln(b) = \\int c ln \\cfrac{a}{b}$, and using the above definitions we have:\n",
      "\n",
      "\\begin{equation}\n",
      "L(Q) = \\int Q_j(\\theta_j) \\cfrac{\\ln \\bar{P}(D,\\theta)}{Q_j(\\theta_j)} \\mathrm{d}\\theta_j$\n",
      "\\end{equation}\n",
      ", which is the KL divergence between $Q_j(\\theta_j)$ and $\\ln \\bar{P}(D,\\theta)\n",
      "\n",
      "Maximizing now $L(Q)$ means that we have to minimize the KL divergence, which occurs only for $Q_j(\\theta_j) = \\bar{P}(D,\\theta)$. From 10.9 (Bishop book) we also that the general expression for this solution is given by:\n",
      "\n",
      "\\begin{equation}\n",
      "\\ln Q_j^*(\\theta_j) = \\langle \\ln P(D,\\theta) \\rangle_{i \\neq j}\n",
      "\\end{equation}\n",
      ", removing the logarithm from the equation we have:\n",
      "\n",
      "\\begin{equation}\n",
      "Q_j^*(\\theta_j) = \\cfrac{\\exp(\\langle \\ln P(D,\\theta) \\rangle_{i \\neq j})}{\\int \\exp(\\langle \\ln P(D,\\theta) \\rangle_{i \\neq j}) \\mathrm{d}\\theta_j}\n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. The log-probability (10 points)\n",
      "\n",
      "Write down the log-prob of data and parameters, $\\ln p(\\mathbf{X}, \\mathbf{Z}, \\mathbf{W}, \\mathbf{\\alpha}, \\tau, \\mathbf{\\mu})$, in full detail (where $\\mathbf{X}$ are observed, $\\mathbf{Z}$ is latent; this is different from [Bishop99] who uses $\\mathbf{T}$ and $\\mathbf{X}$ respectively, but $\\mathbf{X}$ and $\\mathbf{Z}$ are consistent with the PRML book and are more common nowadays). Could we use this to assess the convergence of the variational Bayesian PCA algorithm? If yes, how? If no, why not?\n",
      "\n",
      "#### Answer\n",
      "\n",
      "The log-prob of the data and parameters are given from:\n",
      "\\begin{align*}\n",
      "\\ln P(\\mathbf{X}, \\mathbf{Z}, \\mathbf{W}, \\alpha, \\tau, \\mu) =& \\ln\\left(\\prod_{n=1}^N P(x_{n}|z_{n},W,\\mu,\\tau)P(Z)P(W|a)P(a)P(\\mu)P(\\tau)\\right) \\\\\n",
      "=& \\ln \\left( \\prod_{n=1}^N \\left[ \\left( \\cfrac{\\tau}{2\\pi}\\right)^{d/2} \\exp \\left\\lbrace - \\cfrac{1}{2} \\tau ||x_n - w z_n - \\mu||^2\\right\\rbrace \\right] \\right. \\\\\n",
      "& \\prod_{n=1}^N \\left[ \\left( \\cfrac{1}{2\\pi}\\right)^{q/2} \\exp \\left\\lbrace -\\cfrac{1}{2}  ||z_n||^2 \\right\\rbrace \\right]\\\\\n",
      "& \\prod_{i=1}^q \\left[ \\left( \\cfrac{\\alpha_i}{2\\pi}\\right)^{d/2} \\exp \\left\\lbrace -\\cfrac{1}{2} \\alpha_i ||\\mathbf{w}_i||^2 \\right\\rbrace \\right] \\\\\n",
      "& \\prod_{i=1}^q \\left[ \\cfrac{b_{\\alpha}^{\\alpha_{\\alpha}} \\alpha_i^{\\alpha_{\\alpha - 1}}\\exp \\lbrace -b_{\\alpha}\\alpha_{\\alpha} \\rbrace } {\\Gamma(\\alpha_{\\alpha})} \\right]\\\\\n",
      "& \\left(\\cfrac{\\beta}{2\\pi}\\right)^{d/2} \\exp \\left\\lbrace -\\cfrac{1}{2}\\beta  ||\\mathbf{\\mu}||^2 \\right\\rbrace\\\\\n",
      "& \\left. \\cfrac{d_{\\tau}^{c_{\\tau}} \\tau^{c_{\\tau} - 1} \\exp \\lbrace -\\tau d_{\\tau} \\rbrace }{\\Gamma(c_{\\tau})} \\right)\\\\\n",
      "=& \\ln \\prod_{n=1}^N \\left[ \\left( \\cfrac{\\tau}{2\\pi}\\right)^{d/2} \\exp \\left\\lbrace - \\cfrac{1}{2} \\tau ||x_n - w z_n - \\mu||^2\\right\\rbrace \\right]\\\\\n",
      "& \\ln \\prod_{n=1}^N \\left[ \\left( \\cfrac{1}{2\\pi}\\right)^{q/2} \\exp \\left\\lbrace -\\cfrac{1}{2}  ||z_n||^2 \\right\\rbrace \\right]\\\\\n",
      "& \\ln \\prod_{i=1}^q \\left[ \\left( \\cfrac{\\alpha_i}{2\\pi}\\right)^{d/2} \\exp \\left\\lbrace -\\cfrac{1}{2} \\alpha_i ||\\mathbf{w}_i||^2 \\right\\rbrace \\right] \\\\\n",
      "& \\ln \\prod_{i=1}^q \\left[ \\cfrac{b_{\\alpha}^{\\alpha_{\\alpha}} \\alpha_i^{\\alpha_{\\alpha - 1}}\\exp \\lbrace -b_{\\alpha}\\alpha_{\\alpha} \\rbrace } {\\Gamma(\\alpha_{\\alpha})} \\right]\\\\\n",
      "& \\ln \\left( \\left(\\cfrac{\\beta}{2\\pi}\\right)^{d/2} \\exp \\left\\lbrace -\\cfrac{1}{2}\\beta  ||\\mathbf{\\mu}||^2 \\right\\rbrace \\right)\\\\\n",
      "& \\ln \\cfrac{d_{\\tau}^{c_{\\tau}} \\tau^{c_{\\tau} - 1} \\exp \\lbrace -\\tau d_{\\tau} \\rbrace }{\\Gamma(c_{\\tau})}\\\\\n",
      "=& \\cfrac{dN}{2} \\ln \\left( \\cfrac{\\tau}{2\\pi} \\right) + \\sum_{n=1}^N \\left( - \\cfrac{\\tau}{2} ||x_n - wz_n -\\mu ||^2 \\right)\\\\\n",
      "& + \\cfrac{qN}{2} \\ln \\left( \\cfrac{1}{2\\pi} \\right) + \\sum_{i=1}^N \\left( \\cfrac{1}{2} ||z_n||^2 \\right)\\\\\n",
      "& + \\sum_{i=1}^q \\cfrac{d}{2} \\ln \\cfrac{\\alpha_i}{2\\pi} + \\sum_{i=1}^q \\left( - \\cfrac{\\alpha_i}{2} ||w_i||^2 \\right)\\\\\n",
      "& + q \\ln \\cfrac{b_{\\alpha}^{\\alpha_0}}{\\Gamma(\\alpha_{\\alpha})} + \\sum_{i=1}^q \\left( \\ln \\alpha^{(\\alpha_{\\alpha} - 1)} - b_{\\alpha}\\alpha_{0} \\right)\\\\\n",
      "& + \\cfrac{d}{2} \\ln \\cfrac{\\beta}{2\\pi} - \\cfrac{\\beta}{2} ||\\mu||^2\\\\\n",
      "& + \\ln d_{\\tau}^{c_{\\tau}} + \\ln \\tau^{c_{\\tau} - 1} - \\tau d_{\\tau}\n",
      "\\end{align*}\n",
      "\n",
      "As mentioned in the paper the Bayesian framework does not determine a specific value for the number principal components. Rather, it estimates a posterior distribution over models. The $\\ln P(D,\\theta)$ determines the joint distribution of data and parameters. If we wanted to use this to assess the convergence we would have to use point estimates of the parameters as we cannot use distributions to evaluate $\\ln P(D,\\theta)$. However we don't know if a single value of $Q$ would become higher, when $Q(\\theta)$ tends to be equal to $\\ln P(\\theta|D)$. So we cannot use this method to assess convergence."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. The lower bound $\\mathcal{L}(Q)$ (25 points)\n",
      "\n",
      "Derive an expression for the lower bound $\\mathcal{L}(Q)$ of the log-prob $\\ln p(X)$ for Bayesian PCA, making use of the factorization (eq. 12) and the form of the Q-distributions (eq. 16-20) as listed in [Bishop99]. Show your steps. Implement this function.\n",
      "\n",
      "The following result may be useful:\n",
      "\n",
      "For $x \\sim \\Gamma(a,b)$, we have $\\langle \\ln x\\rangle = \\ln b + \\psi(a)$, where $\\psi(a) = \\frac{\\Gamma'(a)}{\\Gamma(a)}$ is the digamma function (which is implemented in numpy.special)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We used $\\mathbf{X}$ for observed and $\\mathbf{Z}$ for latent\n",
      "\n",
      "\\begin{align*}\n",
      "L(Q)=&\\int Q(\\theta)\\ln\\frac{P(D,\\theta)}{Q(\\theta)}d\\theta\\\\\n",
      "    =&\\int Q(\\theta)\\ln P(D,\\theta) d\\theta - \\int Q(\\theta)\\ln Q(\\theta)d\\theta\\\\\n",
      "    =&\\mathbb{E}[\\ln P(D,\\theta)]- \\mathbb{E}[\\ln Q(\\theta)]\\\\\n",
      "    =&\\mathbb{E}[\\ln\\prod_{n=1}^N P(x_{n}|z_{n},\\mathbf{W},\\mathbf{\\mu},\\tau)] + \\mathbb{E}[\\ln P(Z)] + \\mathbb{E}[\\ln P(\\mathbf{W|\\alpha})] + \\mathbb{E}[\\ln P(\\alpha)] + \\mathbb{E}[\\ln P(\\mu)] + \\mathbb{E}[\\ln P(\\tau)]\\\\\n",
      "    &- \\mathbb{E}[\\ln Q(Z)] - \\mathbb{E}[\\ln Q(\\mathbf{W})] - \\mathbb{E}[\\ln Q(\\alpha)] - \\mathbb{E}[\\ln Q(\\mu)] - \\mathbb{E}[\\ln Q(\\tau)]\\\\\n",
      "    =& \\mathbb{E} \\left[ \\ln \\left( \\prod_{n=1}^{N} \\mathcal{N} (x_{n} | \\mathbf{W}z_{n} +\\mu,\\sigma^2 \\mathbf{I}_{d}) \\right) \\right] + \\mathbb{E} \\left[ \\ln \\left( \\prod_{n=1}^{N} \\mathcal{N}(z_{n}|0, I_q) \\right) \\right] + \\mathbb{E} \\left[ \\ln \\prod_{i=1}^q \\left[ \\left( \\cfrac{\\alpha_i}{2\\pi}\\right)^{d/2} \\exp \\left\\lbrace -\\cfrac{1}{2} \\alpha_i ||\\mathbf{w}_i||^2 \\right\\rbrace \\right] \\right] + \\mathbb{E} \\left[\\ln \\left( \\prod_{i=1}^{q} \\Gamma ( \\alpha_i| a_{\\alpha}, b_{\\alpha}) \\right)  \\right]\\\\\n",
      "    &+\\mathbb{E} \\left[ \\ln \\left( \\mathcal{N}(\\mu|0, \\beta^{-1} I) \\right) \\right] + \\mathbb{E} \\left[ \\ln \\left( \\mathcal{N}(\\mu|0, \\beta^{-1} I) \\right) \\right] + \\mathbb{E}\\left[ \\ln \\left( \\Gamma(\\tau|c_\\tau, d_\\tau ) \\right) \\right] - \\mathbb{E} \\left[ \\ln \\left( \\prod_{n=1}^{N} \\mathcal{N}(z_n| m_z^{(n)}, \\Sigma_z) \\right) \\right] - \\mathbb{E} \\left[ \\ln \\left( \\prod_{k=1}^{d}  \\mathcal{N}(\\widetilde{w}_k | m_w^{(k)}, \\Sigma_w) \\right) \\right]\\\\\n",
      "    &-\\mathbb{E} \\left[ \\ln \\left( \\prod_{i=1}^{q} \\Gamma(\\alpha_i| \\widetilde{a}_\\alpha, \\widetilde{b}_{\\alpha i} ) \\right)\\right] - \\mathbb{E} \\left[ \\ln \\left( \\mathcal{N}(\\mu | m_\\mu, \\Sigma_\\mu) \\right) \\right] - \\mathbb{E} \\left[ \\ln \\left( \\Gamma(\\tau | \\widetilde{a}_\\tau, \\widetilde{b}_\\tau ) \\right) \\right]\n",
      "\\end{align*}\n",
      "\n",
      "We take each term separately:\n",
      "\n",
      "==============================================================================================================================================\n",
      "\\begin{align*}\n",
      "\\mathbb{E} \\left[ \\ln  P(Z) \\right] = & \\mathbb{E} \\left[ \\ln \\left( \\prod_{n=1}^{N} \\mathcal{N}(z_n|0, I_q) \\right) \\right]   \\\\\n",
      "                                    =& \\sum_{n=1}^N \\mathbb{E} \\left( \\ln \\mathcal{N}(z_n|0, I_q) \\right) \\\\\n",
      "                                    =& \\sum_{n=1}^N \\mathbb{E} \\left(-\\frac{1}{2}(z_{n}-0)^T I_{q}^{-1} (z_{n}-0)-\\frac{q}{2} \\ln(2\\pi)-\\frac{1}{2} \\ln |I_q|  \\right)\n",
      "\\end{align*}\n",
      "\n",
      "Where $\\frac{q}{2} \\ln(2\\pi)$ and $\\frac{1}{2} \\ln |I_q|$ are constant and from matrix cookbook: $ \\mathbb{E}_P[x^{T}Ax] = \\text{Tr}(A \\Sigma) + m^{T} A m $ so we have:\n",
      "\n",
      "\\begin{align*}\n",
      "\\mathbb{E} \\left[ \\ln  P(Z) \\right] =& -\\frac{1}{2} \\mathbb{E} \\left[(z_{n}-0)^{T} I_{q}^{-1} (z_{n}-0)\\right]+const\\\\\n",
      "                                    =& -\\frac{1}{2} \\sum_{n=1}^N \\int Q(z_{n}) z_{n}^{T}I_{q}^{-1}z_{n} dz_{n} +const \\\\\n",
      "                                    =& -\\frac{1}{2} \\sum_{n=1}^N \\left( Tr(\\Sigma_{z}I_{q}^{-1})+m_{z}^T I_{q}^{-1}m_{z}^{(n)}+const \\right)\\\\\n",
      "                                    =& -\\frac{N}{2} Tr(\\Sigma_{z}) - \\frac{1}{2} \\sum_{n=1}^N m_{z}^{T} I_{q}^{-1}m_{z}^{(n)} +const\n",
      "\\end{align*}\n",
      "\n",
      "==============================================================================================================================================\n",
      "\\begin{align*}\n",
      "\\mathbb{E} \\left[ \\ln P(W|\\alpha) \\right] =& \\mathbb{E} \\left[ \\ln \\prod_{i=1}^q \\left[ \\left( \\cfrac{\\alpha_i}{2\\pi}\\right)^{d/2} \\exp \\left\\lbrace -\\cfrac{1}{2} \\alpha_i ||\\mathbf{w}_i||^2 \\right\\rbrace \\right] \\right]\\\\\n",
      "                                          =& \\sum_{i=1}^q \\int Q(\\alpha_{i}) \\frac{d}{2} \\ln \\left( \\frac{\\alpha_{i}}{2\\pi} \\right) d\\alpha_{i} - \\frac{1}{2} \\int Q(\\alpha_{i}) \\alpha_{i} w_{i} w_{i}^{T} d\\alpha_{i}\\\\\n",
      "                                          =& \\sum_{i=1}^q \\frac{d}{2} \\int \\ln \\left(\\frac{\\alpha_{i}}{2\\pi}\\right) d\\alpha_{i} - \\frac{1}{2} \\int\\int Q(\\alpha_{i})Q(w_{i})\\alpha_{i}w_{i}w_{i}^{T} d\\alpha_{i} dw_{i}\\\\\n",
      "                                          =& \\sum_{i=1}^q \\frac{d}{2} \\int \\ln(\\alpha_{i})Q(\\alpha_{i}) d\\alpha_{i} - \\frac{d}{2} \\ln(2\\pi)d\\alpha_{i} - \\frac{1}{2} \\int\\int \\alpha_{i} Q(\\alpha_{i}) d\\alpha_{i} w_{i}^{T} w_{i} Q(w_{i}) dw_{i}\\\\\n",
      "                                          =&  \\sum_{i=1}^q \\left[\\frac{d}{2}(\\psi(\\widetilde{a}_{a})-\\ln (\\widetilde{b}_{ai})-\\ln (2\\pi)) - \\frac{1}{2} \\left(Tr(\\Sigma_{w})+m_{w}^{(i)T} m^{(i)}  \\right)\\right]\n",
      "\\end{align*}\n",
      "\n",
      "==============================================================================================================================================\n",
      "\\begin{align*}\n",
      "\\mathbb{E} \\left[ \\ln P(\\alpha) \\right] =& \\mathbb{E} \\left[ \\ln \\left( \\prod_{i=1}^{q} \\Gamma ( \\alpha_i| a_{\\alpha}, b_{\\alpha}) \\right) \\right]\\\\\n",
      "                                        =& \\mathbb{E} \\left[\\sum_{i=1}^q \\ln \\Gamma(\\alpha_i| a_{\\alpha}, b_{\\alpha}) \\right]\\\\\n",
      "                                        =& \\mathbb{E} \\left[\\sum_{i=1}^q \\ln\\left(\\frac{1}{\\Gamma(\\alpha_{\\alpha})} b_{\\alpha}^{\\alpha_{\\alpha}} \\alpha_{i}^{\\alpha_{\\alpha}-1} e^{-b_{\\alpha}\\alpha_{i}}\\right)\\right]\\\\\n",
      "                                        =& \\mathbb{E} \\left[\\sum_{i=1}^q \\left(\\ln \\frac{1}{\\Gamma(\\alpha_{\\alpha})}+ \\alpha_{\\alpha}\\ln b_{\\alpha}+(\\alpha_{\\alpha}-1)\\ln \\alpha_{i} - b_{\\alpha}\\alpha_{i} \\right)\\right]\\\\\n",
      "                                        =& \\sum_{i=1}^q \\int \\ln \\frac{1}{\\Gamma(\\alpha_{\\alpha})}Q(\\alpha_{i}) d\\alpha_{i} + \\sum_{i=1}^q \\int Q(\\alpha_{i})\\alpha_{\\alpha}\\ln b_{\\alpha} d\\alpha_{i} + \\sum_{i=1}^q \\int Q(\\alpha_{i})(\\alpha_{\\alpha}-1)\\ln \\alpha_{i} d\\alpha_{i} + \\sum_{i=1}^q \\int Q(\\alpha_{i})(-b_{\\alpha}\\alpha_{i})d\\alpha_{i}\\\\\n",
      "                                        =& const+(\\alpha_{\\alpha}-1) \\sum_{i=1}^q \\int Q(\\alpha_{i})\\ln \\alpha_{i} d\\alpha_{i} - b_{\\alpha} \\sum_{i=1}^q \\int Q(\\alpha_{i})\\alpha_{i} d\\alpha_{i}\\\\\n",
      "                                        =& const+(\\alpha_{\\alpha}-1) \\sum_{i=1}^q(\\psi(\\widetilde{\\alpha}_{\\alpha}) - \\ln \\widetilde{b}_{\\alpha,i}) - b_{\\alpha}\\sum_{i=1}^q \\left(\\frac{\\widetilde{\\alpha}_{\\alpha}}{\\widetilde{b}_{\\alpha,i}}  \\right)\\\\\n",
      "\\end{align*}\n",
      "\n",
      "==============================================================================================================================================\n",
      "\\begin{align*}\n",
      "\\mathbb{E} \\left[ \\ln P(\\mu) \\right] =& \\mathbb{E} \\left[ \\ln \\left( \\mathcal{N} ( \\mu|0, b^{-1}I) \\right) \\right]\\\\\n",
      "                                     =& \\mathbb{E} \\left[\\ln\\left((2\\pi)^{-\\frac{d}{2}}|\\beta^{-1}I|^{-\\frac{1}{2}} e^{-\\frac{1}{2}\\mu\\mu^{T}\\beta}\\right)\\right]\\\\\n",
      "                                     =& \\mathbb{E} \\left[-\\frac{d}{2}\\ln(2\\pi)-\\frac{1}{2}\\ln(|\\beta^{-1}I|)-\\frac{1}{2}\\mu\\mu^{T}\\beta\\right]\\\\\n",
      "                                     =& const - \\frac{1}{2} \\int \\ln |\\beta^{-1}I| - \\frac{1}{2} \\int Q(\\mu)\\mu\\mu^{T}\\beta d\\mu\\\\\n",
      "                                     =& const - \\frac{\\beta}{2} \\int Q(\\mu)\\mu^{T}\\mu d\\mu\\\\\n",
      "                                     =& const - \\frac{\\beta}{2} <\\mu\\mu^{T}>\\\\\n",
      "                                     =& const - \\frac{\\beta}{2} \\left( Tr|\\Sigma_{\\mu}|+m_{\\mu}m_{\\mu}^{T} \\right)\n",
      "\\end{align*}\n",
      "\n",
      "==============================================================================================================================================\n",
      "\\begin{align*}\n",
      "\\mathbb{E} \\left[ \\ln P(\\tau) \\right] =& \\mathbb{E} \\left[ \\ln \\left( \\Gamma \\left ( \\tau|c_{\\tau}, d_{\\tau}\\right ) \\right) \\right]\\\\\n",
      "                                      =& \\mathbb{E} \\left[ \\ln \\left(\\frac{1}{\\Gamma(c_{\\tau})}+d_{\\tau}^{c_{\\tau}}\\tau^{c_{\\tau}-1}e^{-\\tau d_{\\tau}}\\right)\\right]\\\\\n",
      "                                      =& \\mathbb{E} \\left[ \\ln \\frac{1}{\\Gamma(c_{\\tau})}+c_{\\tau}\\ln d_{\\tau} + (c_{\\tau}-1)\\ln \\tau - \\tau d_{\\tau} \\right]\\\\\n",
      "                                      =& \\int \\ln \\frac{1}{\\Gamma (c_{\\tau})} Q(\\tau) d\\tau + \\int c_{\\tau}\\ln d_{\\tau} Q(\\tau) d_{\\tau} + (c_{\\tau}-1) \\int \\ln \\tau Q(\\tau) d\\tau - d_{\\tau} \\int \\tau Q(\\tau) d\\tau\\\\\n",
      "                                      =& (c_{\\tau}-1) <\\ln \\tau> - d_{\\tau} <\\tau>\\\\\n",
      "                                      =& (c_{\\tau}-1) (\\psi(\\widetilde{a}_\\tau)-\\ln \\widetilde{b}_\\tau) - d_{\\tau} \\frac{\\widetilde{a}_\\tau}{\\widetilde{b}_\\tau} + const \\\\\n",
      "                                      =& (c_{\\tau}-1)(\\frac{\\Gamma ' (\\widetilde{a}_\\tau)}{\\Gamma(\\widetilde{a}_\\tau)}-\\ln \\widetilde{b}_\\tau) - d_{\\tau} \\frac{\\widetilde{a}_\\tau}{\\widetilde{b}_\\tau}+const\n",
      "\\end{align*}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the first term of the lower bound equation we have:\n",
      "\n",
      "\n",
      "\\begin{align*}\n",
      "\\mathbb{E}(\\ln Q(\\theta)) =& \\mathbb{E}(\\ln \\prod_i Q_i(\\theta_i))\\\\\n",
      "=& \\mathbb{E}_Q \\left( \\ln \\prod_{n=1}^N \\mathcal{N}(X_n|m_x,\\Sigma_x)\\right) + \\mathbb{E}_Q \\left( \\ln \\mathcal{N}(\\mathbf{\\mu}|\\mathbf{m_{\\mu}, \\mathbf{\\Sigma}_x})\\right) + \\mathbb{E}_Q \\left( \\ln \\prod_{k=1}^d \\mathcal{N} (\\tilde{w}_k|m_w^{(k)},\\Sigma_w)\\right)\\\\\n",
      "+& \\mathbb{E}_Q \\left( \\ln \\prod_{i=1}^q \\Gamma (a_i | \\tilde{a}_a, \\tilde{b}_{ai})\\right) + \\mathbb{E}_Q \\left( \\ln \\Gamma (\\tau | \\tilde{a}_{\\tau}, \\tilde{b}_{\\tau})\\right)\n",
      "\\end{align*}\n",
      "\n",
      "\n",
      "Now, we are going to expand each term of the above equation:\n",
      "\n",
      "\\begin{align*}\n",
      "\\mathbb{E}_Q \\left( \\ln \\prod_{n=1}^N \\mathcal{N}(X_n|m_x,\\Sigma_x)\\right) &=\\mathbb{E}_Q \\left(\\sum_{n=1}^N \\ln \\mathcal{N}(X_n|m_x,\\Sigma_x) \\right)\\\\\n",
      "&=\\sum_{n=1}^N \\mathbb{E}_Q \\left( \\ln \\left( \\left( \\cfrac{1}{2\\pi}\\right)^{q/2} \\mathbf{\\Sigma_x}^{-1/2} \\exp (-\\frac{1}{2}(\\mathbf{x_n} - \\mathbf{m_x})^T \\mathbf{\\Sigma_x}^{-1}(\\mathbf{x_n} - \\mathbf{m_x}) )\\right) \\right)\\\\\n",
      "&=\\mathbb{E}_Q\\left( \\cfrac{Nq}{2}\\ln \\left( \\cfrac{1}{2\\pi} \\right) \\right) + \\mathbb{E}_Q\\left( \\cfrac{q}{2} \\ln \\mathbf{\\Sigma_x}  \\right) + \\mathbb{E}_Q\\left( \\sum_{n=1}^N (-\\frac{1}{2}(\\mathbf{x_n} - \\mathbf{m_x})^T \\mathbf{\\Sigma_x}^{-1}(\\mathbf{x_n} - \\mathbf{m_x})) \\right)\\\\\n",
      "&=\\mathbb{E}_Q\\left( \\sum_{n=1}^N (-\\frac{1}{2}(\\mathbf{x_n} - \\mathbf{m_x})^T \\mathbf{\\Sigma_x}^{-1}(\\mathbf{x_n} - \\mathbf{m_x})) \\right) + const\\\\\n",
      "&=-\\cfrac{1}{2} \\sum_{n=1}^N \\int Q(x_n) (\\mathbf{x_n} - \\mathbf{m_x})^T \\mathbf{\\Sigma_x}^{-1}(\\mathbf{x_n} - \\mathbf{m_x})\\mathrm{d}x_n + const,\\text{ 3.57 Matrix Cookbook}\\\\\n",
      "&= \\cfrac{N}{2} + Trace(\\Sigma_x \\Sigma_x^{-1}) + const\\\\\n",
      "&= \\cfrac{Nq}{2} +const\n",
      "\\end{align*}\n",
      "\n",
      "==============================================================================================================================================\n",
      "\\begin{equation*}\n",
      "\\mathbb{E}_Q \\left( \\ln \\mathcal{N}(\\mathbf{\\mu}|\\mathbf{m_{\\mu}, \\mathbf{\\Sigma}_x})\\right) =  const\\text{, similar to the previous derivation.} \\\\\n",
      "\\end{equation*}\n",
      "\n",
      "==============================================================================================================================================\n",
      "\\begin{equation*}\n",
      "\\mathbb{E}_Q \\left( \\ln \\prod_{k=1}^d \\mathcal{N} (\\tilde{w}_k|m_w^{(k)},\\Sigma_w)\\right) =  const\\text{, similar to the previous two derivations.} \\\\\n",
      "\\end{equation*}\n",
      "\n",
      "==============================================================================================================================================\n",
      "\\begin{align*}\n",
      "\\mathbb{E}_Q \\left( \\ln \\prod_{i=1}^q \\Gamma (a_i | \\tilde{a}_a, \\tilde{b}_{ai})\\right)=& \\mathbb{E}_Q\\left( \\sum_{i=1}^q \\ln \\Gamma (a_i | \\tilde{a}_a, \\tilde{b}_{ai}) \\right)\\\\\n",
      "=& \\mathbb{E}_Q\\left( \\sum_{i=1}^q \\ln \\left( \\cfrac{1}{\\Gamma(\\tilde{a}_a)} b_{\\tilde{a}i}^{\\tilde{a}_a} a_i^{\\tilde{a}_a -1} e^{-\\tilde{b}_{ai}a_i} \\right) \\right)\\\\\n",
      "=& \\mathbb{E}_Q\\left( \\sum_{i=1}^q \\left( - \\ln\\Gamma(\\tilde{a}_a) +\\ln b_{\\tilde{a}i}^{\\tilde{a}_a} +\\ln a_i^{\\tilde{a}_a -1} - \\tilde{b}_{ai}a_i  \\right) \\right)\\\\\n",
      "=& -\\int \\mathrm{d}a_i \\sum_{i=1}^q  Q(a_i) \\ln\\Gamma(\\tilde{a}_a) + \\int \\mathrm{d}a_i \\sum_{i=1}^q  Q(a_i) \\ln b_{\\tilde{a}i}^{\\tilde{a}_a} + \\int \\mathrm{d}a_i \\sum_{i=1}^q  Q(a_i) \\ln a_i^{\\tilde{a}_a -1}\\\\\n",
      "& - \\int \\mathrm{d}a_i \\sum_{i=1}^q  Q(a_i) \\tilde{b}_{ai}a_i\\\\\n",
      "=&\\text{, in which the first two terms are constants...}\\\\\n",
      "=&\\int \\mathrm{d}a_i \\sum_{i=1}^q  Q(a_i) \\ln a_i^{\\tilde{a}_a -1} - \\int \\mathrm{d}a_i \\sum_{i=1}^q  Q(a_i) \\tilde{b}_{ai}a_i +const\\\\\n",
      "=& (\\tilde{a}_a -1)\\sum_{i=1}^q \\int \\mathrm{d}a_i   Q(a_i) \\ln a_i - \\sum_{i=1}^q \\tilde{b}_{ai} \\int \\mathrm{d}a_i  Q(a_i) a_i +const\\\\\n",
      "=&(\\tilde{a}_a -1)\\sum_{i=1}^q \\mathbb{E}_Q[\\ln a_i]  - \\sum_{i=1}^q \\tilde{b}_{ai} \\mathbb{E}_Q[a_i]+const\\\\\n",
      "=& (\\tilde{a}_a -1)\\sum_{i=1}^q \\left( \\cfrac{\\Gamma'(\\tilde{a}_a)}{\\Gamma(\\tilde{a}_a)} - \\ln(\\tilde{b}_{ai})\\right)  - \\sum_{i=1}^q \\tilde{b}_{ai} \\cfrac{\\tilde{a}_a}{\\tilde{b}_{ai}} +const\\\\\n",
      "=& (\\tilde{a}_a -1)\\sum_{i=1}^q \\left( \\cfrac{\\Gamma'(\\tilde{a}_a)}{\\Gamma(\\tilde{a}_a)} - \\ln(\\tilde{b}_{ai})\\right)  - q \\tilde{a}_a +const\n",
      "\\end{align*}\n",
      "\n",
      "==============================================================================================================================================\n",
      "\\begin{align*}\n",
      "\\mathbb{E}_Q \\left( \\ln \\Gamma (\\tau | \\tilde{a}_{\\tau}, \\tilde{b}_{\\tau})\\right) =\n",
      "&\\mathbb{E}_Q \\left( \\ln \\left( \\cfrac{1}{\\Gamma(\\tilde{a}_{\\tau})} \\tilde{b}_{\\tau}^{\\tilde{a}_{\\tau}} \\tau^{\\tilde{a}_{\\tau} -1 } e^{-\\tilde{b}_{\\tau} \\tau} \\right) \\right)\\\\\n",
      "=&\\mathbb{E}_Q \\left( \\ln \\cfrac{1}{\\Gamma(\\tilde{a}_{\\tau})} + \\ln \\tilde{b}_{\\tau}^{\\tilde{a}_{\\tau}}+\\ln \\tau^{\\tilde{a}_{\\tau} -1 } + \\ln e^{-\\tilde{b}_{\\tau} \\tau} \\right)\\\\\n",
      "=&\\mathbb{E}_Q \\left( \\ln \\cfrac{1}{\\Gamma(\\tilde{a}_{\\tau})} + \\ln \\tilde{b}_{\\tau}^{\\tilde{a}_{\\tau}}+\\ln \\tau^{\\tilde{a}_{\\tau} -1 } -\\tilde{b}_{\\tau} \\tau \\right)\\\\\n",
      "=& \\mathbb{E}_Q \\left( \\ln \\cfrac{1}{\\Gamma(\\tilde{a}_{\\tau})} \\right) + \\mathbb{E}_Q \\left( \\ln \\tilde{b}_{\\tau}^{\\tilde{a}_{\\tau}} \\right) + \\mathbb{E}_Q \\left( \\ln \\tau^{\\tilde{a}_{\\tau} -1 } \\right) + \\mathbb{E}_Q \\left( -\\tilde{b}_{\\tau} \\tau \\right)\\\\\n",
      "=&\\int \\mathrm{d}\\tau Q(\\tau)\\ln \\cfrac{1}{\\Gamma(\\tilde{a}_{\\tau})}  + \\int \\mathrm{d}\\tau Q(\\tau)\\ln \\tilde{b}_{\\tau}^{\\tilde{a}_{\\tau}}  + \\int \\mathrm{d}\\tau Q(\\tau) \\ln \\tau^{\\tilde{a}_{\\tau} -1 } + \\int \\mathrm{d}\\tau  Q(\\tau) -\\tilde{b}_{\\tau} \\tau\\\\\n",
      "&\\text{, in which the first two terms are constants as they are independent of tau.}\\\\\n",
      "=& \\int \\mathrm{d}\\tau Q(\\tau) \\ln \\tau^{\\tilde{a}_{\\tau} -1 } + \\int \\mathrm{d}\\tau  Q(\\tau) (-\\tilde{b}_{\\tau} \\tau) + const\\\\\n",
      "=& (\\tilde{a}_{\\tau} -1) \\int \\mathrm{d}\\tau Q(\\tau) \\ln \\tau - \\tilde{b}_{\\tau}\\int \\mathrm{d}\\tau  Q(\\tau) \\tau+ const\\\\\n",
      "=&(\\tilde{a}_{\\tau} -1) \\mathbb{E}_Q(\\ln \\tau) - \\tilde{b}_{\\tau} \\mathbb{E}_Q(\\tau)+ const\\\\\n",
      "=&(\\tilde{a}_{\\tau} -1)\\left( \\cfrac{\\Gamma'(\\tilde{a}_{\\tau})}{\\Gamma(\\tilde{a}_{\\tau})} - \\ln(\\tilde{b}_{\\tau}) \\right) - \\tilde{b}_{\\tau} \\cfrac{\\tilde{a}_{\\tau}}{\\tilde{b}_{\\tau}}+ const\\\\\n",
      "=&(\\tilde{a}_{\\tau} -1)\\left( \\cfrac{\\Gamma'(\\tilde{a}_{\\tau})}{\\Gamma(\\tilde{a}_{\\tau})} - \\ln(\\tilde{b}_{\\tau}) \\right) - \\tilde{a}_{\\tau}+ const\n",
      "\\end{align*}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So the Lower Bound equation can be written:\n",
      "\\begin{align*}\n",
      "L(Q)=& -\\frac{N}{2} Tr(\\Sigma_{z}) - \\frac{1}{2} \\sum_{n=1}^N m_{z}^{T} I_{q}^{-1}m_{z}^{(n)} \\\\\n",
      "    +& \\sum_{i=1}^q \\left[\\frac{d}{2}(\\psi(\\widetilde{a}_{a})-\\ln (\\widetilde{b}_{ai})-\\ln (2\\pi)) - \\frac{1}{2} \\left(Tr(\\Sigma_{w})+m_{w}^{(i)T} m^{(i)}  \\right)\\right] \\\\\n",
      "    +& (\\alpha_{\\alpha}-1) \\sum_{i=1}^q(\\psi(\\widetilde{\\alpha}_{\\alpha})- \\ln \\widetilde{b}_{\\alpha,i}) - b_{\\alpha}\\sum_{i=1}^q \\left(\\frac{\\widetilde{\\alpha}_{\\alpha}}{\\widetilde{b}_{\\alpha,i}} \\right)\\\\\n",
      "    -& \\frac{\\beta}{2} \\left( Tr|\\Sigma_{\\mu}|+m_{\\mu}m_{\\mu}^{T} \\right)\\\\\n",
      "    +& (c_{\\tau}-1)(\\frac{\\Gamma ' (\\widetilde{a}_\\tau)}{\\Gamma(\\widetilde{a}_\\tau)}-\\ln \\widetilde{b}_\\tau) - d_{\\tau} \\frac{\\widetilde{a}_\\tau}{\\widetilde{b}_\\tau}\\\\\n",
      "    +& \\cfrac{Nq}{2}\\\\\n",
      "    +& (\\tilde{a}_a -1)\\sum_{i=1}^q \\left( \\cfrac{\\Gamma'(\\tilde{a}_a)}{\\Gamma(\\tilde{a}_a)} - \\ln(\\tilde{b}_{ai})\\right)  - q \\tilde{a}_a \\\\\n",
      "    +& (\\tilde{a}_{\\tau} -1)\\left( \\cfrac{\\Gamma'(\\tilde{a}_{\\tau})}{\\Gamma(\\tilde{a}_{\\tau})} - \\ln(\\tilde{b}_{\\tau}) \\right) - \\tilde{a}_{\\tau}\\\\\n",
      "    +& const\n",
      "\\end{align*}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The $\\mathbb{E}[\\ln\\prod_{n=1}^N P(x_{n}|z_{n},\\mathbf{W},\\mathbf{\\mu},\\tau)]$ is missing so we couldn't complete the lower bound"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 5. Optimize variational parameters (50 points)\n",
      "Implement the update equations for the Q-distributions, in the __update_XXX methods. Each update function should re-estimate the variational parameters of the Q-distribution corresponding to one group of variables (i.e. either $Z$, $\\mu$, $W$, $\\alpha$ or $\\tau$)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All functions have been implemented. (see code at the beginning)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 6. Learning algorithm (10 points)\n",
      "Implement the learning algorithm described in [Bishop99], i.e. iteratively optimize each of the Q-distributions holding the others fixed.\n",
      "\n",
      "What would be a good way to track convergence of the algorithm? Implement your suggestion.\n",
      "\n",
      "Test the algorithm on some test data drawn from a Gaussian with different variances in orthogonal directions. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean = np.zeros(10)\n",
      "cov = np.diag([5,4,3,2,1,1,1,1,1,1])\n",
      "X = np.random.multivariate_normal(mean,cov,100).T\n",
      "vPca = BayesianPCA(10,100)\n",
      "vPca.fit(X, 1000)\n",
      "# vPca.CheckFittedModel(X)\n",
      "# http://wiki.scipy.org/Cookbook/Matplotlib/HintonDiagrams\n",
      "vPca.hinton()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fitting the model...\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000 iterations done\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAEACAYAAACXqUyYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x58e2358>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The result of fitting a maximum likelihood PCA model on test data from a Gaussian are\n",
      "shown in the above hinton diagram. As we can see the algorithm doesn't seem to run correctly. A good way to track convergence of the algorithm is through the lower bound. The algorithm should stop running when the lower bound is not increasing anymore. We tried to implement the lower bound but it is not complete. So we run our implementation with fixed iterations "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 7. PCA Representation of MNIST (10 points)\n",
      "\n",
      "Download the MNIST dataset from here http://deeplearning.net/tutorial/gettingstarted.html (the page contains python code for loading the data). Run your algorithm on (part of) this dataset, and visualize the results.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = gzip.open('mnist.pkl.gz', 'rb')\n",
      "train_set, valid_set, test_set = cPickle.load(f)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We downloaded the MNIST dataset and we performed bayesian PCA learning on four random images inside the train_set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_ex = 4\n",
      "for example in range(n_ex):\n",
      "    print \"example: \",example+1,\"/\",n_ex\n",
      "    rand = random.random_integers(len(train_set[0]))\n",
      "    vPca = BayesianPCA(28,28)\n",
      "    X = train_set[0][rand].reshape((28,28))\n",
      "    vPca.fit(X, 1000)\n",
      "    matshow(vPca.means_w,cmap=cm.gray)\n",
      "    show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "example:  1 / 4\n",
        "fitting the model...\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000 iterations done\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD7CAYAAABOrvnfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyP8BUtIGOrfd/8UAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0xad99ef0>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "example:  2 / 4\n",
        "fitting the model...\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000 iterations done\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD7CAYAAABOrvnfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGsJJREFUeJzt3XlQlPf9B/D3JqLG4h05IkYIgSgoiBKvqmgEjyZewXi0\nWhpwTOyRWh2n1k4rZhIldhIHjWliqpFUazRWrK0XGkUjHkwSSOptFQgi4IEaUaNont8f+bEDuvv5\n6OKy237frxlmYN88u18f9uOzu9/LZlmWBSIywkOebgAR1R8WPJFBWPBEBmHBExmEBU9kEBY8kUHq\npeC3bNmCDh06ICwsDG+88UZ9POR9CQ4ORlRUFGJiYtC9e3dPNwfJycnw9/dH586d7bdVVFQgISEB\n4eHhGDRoEC5duuRV7UtNTUVQUBBiYmIQExODLVu2eKRtxcXFGDBgACIjI9GpUycsXLgQgPecP2ft\nq7fzZ7nZrVu3rNDQUKugoMC6efOmFR0dbR0+fNjdD3tfgoODrQsXLni6GXa7d++2vvjiC6tTp072\n22bMmGG98cYblmVZVlpamvXb3/7WU81z2L7U1FTrzTff9FibqpWWllp5eXmWZVnWlStXrPDwcOvw\n4cNec/6cta++zp/br/C5ubl48sknERwcDB8fH4wbNw7/+Mc/3P2w983yovFHffv2RcuWLWvdtmHD\nBiQlJQEAkpKSsH79ek80DYDj9gHecQ4DAgLQpUsXAICvry86duyIkpISrzl/ztoH1M/5c3vBl5SU\noF27dvafg4KC7P9Ab2Gz2RAfH4/Y2Fi8//77nm6OQ+Xl5fD39wcA+Pv7o7y83MMtutuiRYsQHR2N\nlJQUj77lqFZYWIi8vDz06NHDK89fdft69uwJoH7On9sL3mazufsh6iwnJwd5eXnYvHkzFi9ejE8/\n/dTTTRLZbDavO69TpkxBQUEB8vPzERgYiOnTp3u0PZWVlUhMTER6ejqaNm1aK/OG81dZWYnRo0cj\nPT0dvr6+9Xb+3F7wbdu2RXFxsf3n4uJiBAUFufth70tgYCAAoE2bNhg1ahRyc3M93KK7+fv7o6ys\nDABQWloKPz8/D7eoNj8/P3shTZo0yaPnsKqqComJiZg4cSJGjhwJwLvOX3X7JkyYYG9ffZ0/txd8\nbGwsTpw4gcLCQty8eROrV6/G8OHD3f2w9+zatWu4cuUKAODq1avIysqq9emztxg+fDgyMjIAABkZ\nGfYnircoLS21f5+Zmemxc2hZFlJSUhAREYGpU6fab/eW8+esffV2/tz+saBlWZs2bbLCw8Ot0NBQ\na+7cufXxkPfs1KlTVnR0tBUdHW1FRkZ6RfvGjRtnBQYGWj4+PlZQUJC1bNky68KFC9bAgQOtsLAw\nKyEhwbp48aLXtG/p0qXWxIkTrc6dO1tRUVHWiBEjrLKyMo+07dNPP7VsNpsVHR1tdenSxerSpYu1\nefNmrzl/jtq3adOmejt/Nsvygo9WiahecKQdkUFY8EQGYcETGYQFT2QQlwve2yfEEJEDrny0fy8T\nYkJDQy0A/OIXvzzw1b59e4e12wAuqDkhBoB9QkzHjh3tv3Py5EksWLDA/vOWLVswZMgQ+8+FhYXi\nYxQVFYl5v379xLxr165iPmfOnFo/FxQUICQkxP7zlClTxOMbNmwo5hUVFWKuTd6oOf8A+P6c15y6\n26ZNG/H48PBwMdfGat/LWPPQ0FD79+vWrcPzzz9fK7927Zp4/IkTJ8T8lVdeEfN33nlHzKOjo+3f\nr127FqNHj66Vz58/v06Pn5WVJeba3yAhIcH+/bJly5CcnFwr/+6778Tjd+7c6TRLTU11eLtLL+n/\nGybEENHdXCp4T088ICLXuPSS/l4nxNRcteORRx5x5aHqTYsWLTzdBFHbtm093QRRzbdz3igiIsLT\nTRDFxMTU6fiCggL1bTLgYsHXnBDz2GOPYfXq1Vi1atVdv1fzPbu3c7SggzdhwdfN/3rBh4SE1PoM\nateuXQ5/z6WCb9CgAd5++20MHjwYt2/fRkpKitf/wYkIcNvkGZvNVmvK351qTg105OmnnxbzCxcu\niPmOHTvEXJse2aFDBzH/+uuvxTwyMlLMf/3rX4v52LFjxVy7IsybN0/MJ0+eLOatW7cWcwB46CH5\nIyBtfMasWbPEfP/+/WKenZ0t5j//+c/F3MfHR8z37Nkj5r179xbzmr1UjgwePFjMDx48KObSc+yP\nf/yjwyWzONKOyCAseCKDsOCJDMKCJzIIC57IICx4IoOw4IkM4tLAm3slzWbSZkp16tRJzLWZWFof\npzRGAAD++c9/ivmdmxvcSZvNNmDAADG/fPmymDdq1EjMtX78lStXinlaWpqYA/qciv79+4u5Ntza\n19dXzEeNGiXm2oxArf2nTp0S8zFjxoi59jdo1qyZmFevo+9MWFiYmDvCKzyRQVjwRAZhwRMZhAVP\nZBAWPJFBWPBEBmHBExnErf3w0nzdAwcOiMdqq75q/dRRUVFifubMGTFv3769mL/77rtirvXB3rkq\n7Z1u374t5tu3bxdzbb58z549xVybaw7o/eTafPOPP/5YzBs0kJ+ecXFxYn79+nUxHzZsmJg/8cQT\nYq49h7R+dm3NhM8//1zMb968KeaO8ApPZBAWPJFBWPBEBmHBExmEBU9kEBY8kUFY8EQGcWs//NGj\nR51mWj/x+fPnxbxbt25irvWR3rhxQ8y1dfM/+OADMa+5s6oj2s6g2nz7lJQUMV+xYoWYa/P172X3\n2M8++0zMk5KSxFxb913rx/7222/FXJvvrj3+vn37xFxb00Hb20DbvEWbD6/tC+DwmPs+goj+a7Hg\niQzCgicyCAueyCAseCKDsOCJDMKCJzJInfrhg4OD0axZMzz88MPw8fFBbm7uPR+rzRfX5kp/9NFH\nYj5jxgwx1+a7//vf/xbzoqIiMe/evbuYnz17Vsy1/edPnz4t5i1atBDzJUuWiPmzzz4r5gAQHx8v\n5lu3bhXzrl27inl+fr6Ya38Df39/Mdfmy2v7y2vPwebNm4v5hQsXxLx169Ziro01caROBW+z2ZCd\nnY1WrVrV5W6IqJ7U+SW9ZVkPoh1EVA/qVPA2mw3x8fGIjY3F+++//6DaRERuUqeX9Dk5OQgMDMS5\nc+eQkJCADh06oG/fvvZ8586d9u+Dg4MREhJSl4cjIidOnjyp7oUH1LHgAwMDAXw/EWPUqFHIzc2t\nVfDaholE9GCEhobWmrDlbJFTl1/SX7t2DVeuXAEAXL16FVlZWejcubOrd0dE9cDlK3x5ebl9u95b\nt27hJz/5CQYNGvTAGkZED57LBR8SEqL2k168eNFp9tVXX4nHavO5X331VTHX5hJr8/G1ddlrfj7h\niNbHfOvWLTEfN26cmGvr1mtzuX/3u9+JeWZmppgDwODBg8Vcmy9+7NgxMd+1a5eYa2sGJCQkiLm2\nf3zbtm3FXBvLUf2W15lz586JefUF1RmtRhzhSDsig7DgiQzCgicyCAueyCAseCKDsOCJDMKCJzKI\nW9elf+SRR5xmWh+rNpdZo62Zru39ra1prq1br/Wjr1u3TszXr18v5to4ghEjRoi5dn7CwsLEHND7\nobV8x44dYr5y5Uox//vf/y7m2oQubd37gwcPirn0/Aa+H40q0eazb9q0Scxnz57tNPvwww8d3s4r\nPJFBWPBEBmHBExmEBU9kEBY8kUFY8EQGYcETGcSt/fCNGzd2msXFxYnH9ujRQ8xbtmwp5tpiHNp8\neW1d+fDwcDGfNGmSmD/33HNiro1D0NYi8PX1FfOCggIx/9GPfiTmALBw4UIx1+aT9+rVS8y1v5E2\nnzwtLU3M58yZI+baOay5pJQj2nz7Tz75RMy1FaT27t0r5o7wCk9kEBY8kUFY8EQGYcETGYQFT2QQ\nFjyRQVjwRAZxaz98o0aNnGaRkZHisVofr7Z/+8SJE8VcU72rjjPa/u79+vUT8xdeeEHM58+fL+ZD\nhw4Vc2fzoatp4xgeeki/FmjzzbX53MXFxWKu9TP36dNHzLW9A7T912fMmCHm2nx9bf/3MWPGiPmy\nZcvEfNasWWLuCK/wRAZhwRMZhAVPZBAWPJFBWPBEBmHBExmEBU9kELUfPjk5GRs3boSfn5+977ui\nogJjx45FUVERgoODsWbNGrRo0eKuY6V1uVNTU8XH/f3vfy/mhw8fFvOtW7eKuTbXWFu3XqOtK79h\nwwYx19Zc1+aSjx8/XsyXLFki5suXLxdzAPjzn/8s5tq679r+6dr+8m+//baYBwcHi7mPj4+Yv/ba\na2Leu3dvMdf6+fft2yfmjz/+uJiXlJSIuSPqFf7FF1/Eli1bat2WlpaGhIQEHD9+HAMHDlQXGiAi\n76AWfN++fe8albVhwwYkJSUBAJKSktSrGRF5B5few5eXl9uXYPL390d5efkDbRQRuUedx9LbbDan\n+7DV3D+uffv26nsqInLN8ePHcfz4cfX3XCp4f39/lJWVISAgAKWlpfDz83P4e9pClUT0YISHh9da\nWNXZxCWXXtIPHz4cGRkZAICMjAyMHDnSlbshonqmFvz48ePRu3dvHDt2DO3atcMHH3yAmTNnYtu2\nbQgPD8eOHTswc+bM+mgrEdWR+pJ+1apVDm/fvn27eufSutwvv/yyeKzWDz958mQxb9iwoZhrfZha\nH7K2bv27774r5qtXrxZzbW/yPXv2iPnp06fFXOsDb968uZgDwKOPPirm69atE/OBAweKubYmgba2\n/2OPPSbmt27dEnNtXfmLFy+KuTafX+tnj4iIEHOtn98RjrQjMggLnsggLHgig7DgiQzCgicyCAue\nyCAseCKDuHVd+gYNnN+91o+s9aFqe3dr696fOnVKzLX58s7GJ1SbNm2amGvr6mvr2l++fFnMY2Nj\nxfzmzZtirs0VB4CAgAAx1/q5jx07JubaWIKaQ0kdkfZFAIDs7Gwx1/YOyMnJEXPtb3D+/Hkxv3Na\n+p2io6PF3BFe4YkMwoInMggLnsggLHgig7DgiQzCgicyCAueyCBu7Yfv0KGD00xb+HLjxo1irvUj\na+u2V1VVibnWvtDQUDFfsGCBmGuaNGki5lFRUWKelZUl5sOHDxdzbd18ALh+/bqYa2MhtJWStHXn\ntfn4Y8eOFfPBgweLuTbWo2fPnmIujUMBgKtXr4q5Nl/+m2++EXNHeIUnMggLnsggLHgig7DgiQzC\ngicyCAueyCAseCKDuLUfXtpL7uOPPxaPnT59upi3b99ezG/cuCHmL730kphrc7G7du0q5mfOnBHz\niooKMe/Tp4+YHzhwQMy7dOki5tpca+38Avp896CgIDE/evSomMfHx4v5D37wgzrdf/WGqM4cPnxY\nzCsrK8X8yy+/FHNtXf42bdqIubamgiO8whMZhAVPZBAWPJFBWPBEBmHBExmEBU9kEBY8kUFslmVZ\n0i8kJydj48aN8PPzs/f7paam4i9/+Yu9n3DevHkYMmRI7Tu22cT50M8++6zYMK2PUdv/XVtXvmnT\npmJus9nEXDltyMvLE/PRo0eLebdu3cT81VdfFfOHHpL/L58wYYKYa+veA/qaAmVlZWKu7T1w9uxZ\nMdf6qbVxAkeOHBHz/v37i/ncuXPFPCYmRsy1f7821qJ3795Os1/96lcOn6PqFf7FF1+8a5CGzWbD\ntGnTkJeXh7y8vLuKnYi8k1rwffv2RcuWLe+6XbvCEZH3cfk9/KJFixAdHY2UlBRcunTpQbaJiNzE\npYKfMmUKCgoKkJ+fj8DAQKfj3s+ePWv/0tbvIiLXnThxAps2bbJ/OePS5Bk/Pz/795MmTcKwYcPU\n3yMi9wkLC0NYWJj9582bNzv8PZeu8KWlpfbvMzMz1U/Eicg7qFf48ePHY9euXTh//jzatWuHOXPm\nIDs7G/n5+bDZbAgJCcF7771XH20lojpS++FdvmObDW+++abTXFv3XVvTXPugcNu2bWI+aNAgMT90\n6JCYa/u3t2jRQsz37Nkj5kOHDhXzDz/8UMy1+exPPfWUmAcGBoo5APz1r38V85qvBB0ZNWqUmB8/\nflzMtTUJtLEcTz/9tJgXFxeLubamQdu2bcVcG0ewa9cuMZeeQ/v373etH56I/new4IkMwoInMggL\nnsggLHgig7DgiQzCgicyiFvXpZf2r3744YfFY9euXSvmsbGxYv7MM8+IeUFBgZhre49r88UbN24s\n5teuXRNzbX92Hx8fMW/UqJGYa3uLa3PdAf1vGB4eLubZ2dli3qxZMzHX1o0/f/68mGt7D2h/Iy1v\n1aqVmL/11lti/vLLL4v5gAEDnGbO1pvgFZ7IICx4IoOw4IkMwoInMggLnsggLHgig7DgiQzi1n74\n5s2bO812794tHqv1s2tLYxcWFor5448/Luba/vXaXOiTJ0+KudbHum/fPjHX5lJr+8O/9tprYt6k\nSRMxB/R/g/Y31sY6REVFibm28Iq29r72N9aeY76+vmKuzaefOXOmmP/tb38Tc22cgyO8whMZhAVP\nZBAWPJFBWPBEBmHBExmEBU9kEBY8kUHc2g9/8eJFp1mvXr3EY69fvy7me/fuFXNtf/fQ0FAx1/rp\ntf3ltT7mO7fgvpO2v7u2ZrtGO//Lly9X70PanxwA/P39xfzbb78V8y+//FLMtf3btbEQDRs2FHNn\nc8qrZWRk1On+r1y5IuZaP/+pU6fE3BFe4YkMwoInMggLnsggLHgig7DgiQzCgicyCAueyCBiP3xx\ncTF++tOf4uzZs7DZbJg8eTJeeeUVVFRUYOzYsSgqKkJwcDDWrFnjcD90aY9xbc1wTcuWLcV8//79\nYq71EcfExIj5uXPn6nT/2rr42nz4vn37ivm2bdvE/NChQ2Ku9dMDwIEDB8Rc66fX9k+/ffu2mGvz\n2bVzpK29r51DPz8/Mdf6yaX1IgAgKChIzI8cOSLmjohXeB8fHyxYsACHDh3C/v37sXjxYhw5cgRp\naWlISEjA8ePHMXDgQKSlpd33AxNR/RMLPiAgwL5yiq+vLzp27IiSkhJs2LABSUlJAICkpCSsX7/e\n/S0lojq75/fwhYWFyMvLQ48ePVBeXm5/yerv74/y8nK3NZCIHpx7GktfWVmJxMREpKen3zWG3Gaz\nOR23/q9//cv+fXh4uEtrcBGRrqysDGVlZervqQVfVVWFxMRETJw4ESNHjgTw/VW9rKwMAQEBKC0t\ndfrhxXPPPXefzSYiVwQEBCAgIMD+81dffeXw98SX9JZlISUlBREREZg6dar99uHDh9tnCmVkZNj/\nIyAi7yZe4XNycrBixQpERUXZu6nmzZuHmTNnYsyYMVi6dKm9W46IvJ/NsizLLXdss2H27NlOc22u\nszYXWJprDwATJ04Uc+39TlhYmJjn5+eL+axZs8T8l7/8pZhre69rfeALFy4U89zcXDEPDg4WcwA4\ne/asmO/Zs0fMf/jDH4r5xo0bxVx7y/jFF1+IubYmwtKlS8X8mWeeEXNtTQft8b/++msxHzFihNNs\nyJAhcFTaHGlHZBAWPJFBWPBEBmHBExmEBU9kEBY8kUFY8EQGcWs//JIlS5zmTz31lHi81k++c+dO\nMdfG7Wt9oLdu3RJzba7zJ598Iuba/u2NGzcWc23d/M6dO4t5Xl6emF+6dEnMAeDEiRNi/sILL4h5\nSUmJmN+4cUPMKyoqxDwiIkLMt27dKuYhISFiHhcXJ+alpaViru2dcOHCBTF/4oknnGb9+/dnPzyR\n6VjwRAZhwRMZhAVPZBAWPJFBWPBEBmHBExnErfvD+/j4OM26du0qHvvRRx+JudZHe+zYsTrljRo1\nEnNtzXBt73Jtb/QmTZqIubauv7b/fKtWrcRcW5MdAHr27CnmZ86cEXNtPv2jjz4q5p9//rmYa88x\nbU0FbU0GbayItv+7tu7+1atXxVz79zvCKzyRQVjwRAZhwRMZhAVPZBAWPJFBWPBEBmHBExnErf3w\nv/nNb5xmN2/eFI/V5iJrfbQHDx4U8wYN5H+6ti79N998I+ZvvfWWmM+fP1/MnW0VVG3v3r1irvXz\nT5s2Tcy7d+8u5gDw2Wefibk2VkFbe//w4cNirs35z8nJEfNf/OIXYq6N1dCWktC2UR82bJiYa2sS\n3LnP473gFZ7IICx4IoOw4IkMwoInMggLnsggLHgig4gFX1xcjAEDBiAyMhKdOnWyb0GcmpqKoKAg\nxMTEICYmRp2KSUTeQVyXvqysDGVlZejSpQsqKyvRrVs3rF+/HmvWrEHTpk3FvlybzYY//elPTnOt\nH1vrY9TWRK+qqhLzgQMHirnWPmmuP6DvDa7Nd9dofczav087P9o4AAAoLCwUc21/9j/84Q9irs2n\n19Ys0NZU0PaXT05OFvP09HQx1/YWCAgIEPPly5eL+fPPP+80mz17tsNxAuLok4CAAHujfH190bFj\nR/vmAW7av4KI3Oie38MXFhYiLy/PvsrJokWLEB0djZSUlHvapYSIPO+eCr6yshKjR49Geno6fH19\nMWXKFBQUFCA/Px+BgYGYPn26u9tJRA+AOpa+qqoKiYmJmDBhAkaOHAkA8PPzs+eTJk1yOiY4KyvL\n/n1oaKi6nxsRuaagoED9TAVQCt6yLKSkpCAiIgJTp061315aWorAwEAAQGZmptNJDIMGDbqPJhOR\nq0JCQmpNOMvOznb4e2LB5+TkYMWKFYiKikJMTAwAYO7cuVi1ahXy8/Nhs9kQEhKC995778G1nIjc\nRiz4Pn364Lvvvrvr9qFDh7qtQUTkPm7dH37IkCFOc20usrOXJNW0udba3uBr164V8379+ol5eXm5\nmGv99NLe3oA+zkA7PjMzU8yr35I5o7Uf0MdKtGvXTsy3b98u5tqFpeZnRI5MnjxZzH/2s5+J+Y9/\n/GMxj4yMFHNtQJr2HNU0bNjQafbSSy9xf3gi07HgiQzCgicyCAueyCAseCKDsOCJDMKCJzKIW/vh\n9+3b5zQ/evSoePzixYvFfPfu3WL++uuvi3nr1q3FXJsvXlpaKubVIxOduXz5spj7+/vX6fG1GYza\nmvDx8fFiDgDvvPNOne5D6+vXxgoUFRWJuTaf3maziXmvXr3EfOXKlWL+5JNPirn2N5T62QH5Obpg\nwQL2wxOZjgVPZBAWPJFB6q3gtfXNPO0///mPp5sgOnTokKebICorK/N0E0SnTp3ydBNExcXF9fI4\nLPj/5+0Fr22s6GnaZCJP8/aCP336dL08Dl/SExmEBU9kEstN4uLiLAD84he/PPAVFxfnsC7dNvCG\niLwPX9ITGYQFT2QQFjyRQVjwRAZhwRMZ5P8AvVHg27ubI7MAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0xadd4d68>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "example:  3 / 4\n",
        "fitting the model...\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000 iterations done\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD7CAYAAABOrvnfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGppJREFUeJzt3XtQ1NfZB/DvalCToEls5CKQQBUURBYUL1ERraJJNN5I\na2xEqlinZqZRY1LNtLE4mSbkj4xjjG1t1JbExmhMUeNt1IkXpElMFcS7Ri4iAl7wBsSI5vf+8b7u\ngO4+jy5Zdt+e72eGGeHL7h5+4ckue855js2yLAtEZIQW3h4AETUfFjyRQVjwRAZhwRMZhAVPZBAW\nPJFBmqXgt2zZgq5duyIyMhLvvPNOczzkfQkPD0dcXBwSEhLQu3dvbw8HU6ZMQWBgILp37+74WnV1\nNVJSUhAVFYVhw4bh8uXLPjW+zMxMhIaGIiEhAQkJCdiyZYtXxlZWVobBgwejW7duiI2NxXvvvQfA\nd66fq/E12/WzPOzmzZtWp06drOLiYuvGjRuW3W63jhw54umHvS/h4eHWxYsXvT0Mh927d1v79++3\nYmNjHV977bXXrHfeeceyLMvKysqy5syZ463hOR1fZmam9e6773ptTLdVVFRY+fn5lmVZ1rVr16yo\nqCjryJEjPnP9XI2vua6fx5/h9+7di86dOyM8PBx+fn544YUXsG7dOk8/7H2zfGj9UVJSEh577LFG\nX1u/fj3S09MBAOnp6Vi7dq03hgbA+fgA37iGQUFBiI+PBwD4+/sjOjoa5eXlPnP9XI0PaJ7r5/GC\nLy8vR1hYmOPz0NBQxw/oK2w2G4YOHYrExER88MEH3h6OU1VVVQgMDAQABAYGoqqqyssjutuiRYtg\nt9uRkZHh1T85bispKUF+fj769Onjk9fv9vj69u0LoHmun8cL3mazefohmiwvLw/5+fnYvHkzFi9e\njNzcXG8PSWSz2Xzuuk6fPh3FxcUoKChAcHAwZs+e7dXx1NTUIDU1FQsXLkTbtm0bZb5w/WpqavD8\n889j4cKF8Pf3b7br5/GCDwkJQVlZmePzsrIyhIaGevph70twcDAAoEOHDhg7diz27t3r5RHdLTAw\nEJWVlQCAiooKBAQEeHlEjQUEBDgKaerUqV69hvX19UhNTUVaWhrGjBkDwLeu3+3xTZw40TG+5rp+\nHi/4xMREnDx5EiUlJbhx4wZWrVqFUaNGefph71ldXR2uXbsGAKitrcXWrVsbvfvsK0aNGoXs7GwA\nQHZ2tuMXxVdUVFQ4/p2Tk+O1a2hZFjIyMhATE4OZM2c6vu4r18/V+Jrt+nn8bUHLsjZt2mRFRUVZ\nnTp1st56663meMh7VlRUZNntdstut1vdunXzifG98MILVnBwsOXn52eFhoZay5cvty5evGgNGTLE\nioyMtFJSUqxLly75zPiWLVtmpaWlWd27d7fi4uKs0aNHW5WVlV4ZW25urmWz2Sy73W7Fx8db8fHx\n1ubNm33m+jkb36ZNm5rt+tksywfeWiWiZsGVdkQGYcETGYQFT2QQFjyRQdwueF/fEENETrjz1v69\nbIgJCAiwAPCDH/zwwkenTp2c1u4DcEPDDTEAHBtioqOjHd9z7tw5pKWlOT4/cOAA7Ha74/P27duL\nj6Etbx0+fLiYnz17VsyTkpIafb5u3TqMHj3a8fn27dvF29fU1Ih5x44dxby+vl7Me/Xq1ejzDRs2\nYOTIkY7PP//8c/H22quuv/zlL2IeExMj5kDjn2HLli14+umnG+VdunQRb79582Yx//e//y3mdy6Z\nvdNTTz3l+Hdubu5d/81DQkLE299ekOVKQkKCmP/1r38V84b1sHPnTgwaNKhRri3//clPfuIye/nl\nl51+3a2X9P8fNsQQ0d3cKnhvbzwgIve49ZL+XjfEHDhwwPFvPz8/dx6q2WgvP70tKirK20MQde7c\n2dtDED3xxBPeHoLo9p/H7jp58iROnjypfp9bBd9wQ0zHjh2xatUqrFy58q7va/g3iq/r2rWrt4cg\nYsE3zZNPPuntIYiaWvCRkZGIjIx0fO6qRZZbBf/AAw/g/fffx/Dhw3Hr1i1kZGQ0esOOiHyTxzbP\n2Gw2zJkzx2V+4sQJ8fbjx48X8/Pnz4t5u3btxPzw4cNirrl69aqY9+/fX8xLSkrEXOsZUFpaKuan\nTp0S82effVbMjx49KuaA/k7+pk2bxPxXv/qVmGszITdv3hTzwsLCJt2+trZWzI8dOybmQUFBYq5d\nvxYt5LfYrl+/7jL7/e9/77RlFlfaERmEBU9kEBY8kUFY8EQGYcETGYQFT2QQFjyRQdxaeHOvnB1H\ndFvDnXTO5OXlibk2Rztu3Dgxd7YysCFtN542D6/l3377rZjv3r1bzCMiIsRcW5mn7QS7deuWmAON\nl047I+3mAoBly5aJeatWrcQ8NjZWzC9cuCDm2nLvAQMGiLl2je7cnXcnbcOZdv+HDh0Sc2f4DE9k\nEBY8kUFY8EQGYcETGYQFT2QQFjyRQVjwRAbx6Dz8nZ1XG3rttdfE206ePNnt+waAffv2ifmrr74q\n5rt27RLzsWPHirm2jiAxMVHMv/jiCzHX9vufOXNGzP39/cX89OnTYg7o8+BLliwR81mzZol5wzZq\nzmjz0JcuXRLz4OBgMdf2w3fo0EHMf/jhBzHXejI07LrrjDtdmvgMT2QQFjyRQVjwRAZhwRMZhAVP\nZBAWPJFBWPBEBvFoX/rXX3/dZT5w4EDx9uvWrRNz7eRP7fTYfv36ibk2j96zZ08x/+yzz8Rcm2PV\n9vtrxwq98cYbYr5mzRox1+agAf1n0Pb8az/j448/LubayUZVVVVirp1Oq50ArJ2NoN3/kCFDxFwz\nYcIEl1l8fDz70hOZjgVPZBAWPJFBWPBEBmHBExmEBU9kEBY8kUGatB8+PDwc7dq1Q8uWLeHn54e9\ne/c2ynfs2OHytvX19eJ9T5o0ScxzcnLUsUmWLl0q5tpe7+TkZDHXzm/X1hFcvnxZzD/66CMx37Bh\ng5hrPePvZa91cXGxmGs9Cb766isx19ZqPPCA/Ou7ZcsWMdf+G2o9CUaPHi3moaGhYq6tQ5DOdQCA\nDz74QMydaVLB22w27Ny5E+3bt2/K3RBRM2nyS3oPLdQjIg9oUsHbbDYMHToUiYmJbr28IKLm1aSX\n9Hl5eQgODsb58+eRkpKCrl27NjpPq2FPsnbt2uGRRx5pysMRkQvl5eXqWXVAEwv+dhPADh06YOzY\nsdi7d2+jgg8LC2vK3RPRPQoJCWn0RvA333zj9PvcfklfV1fnOIG0trYWW7duRffu3d29OyJqBm4/\nw1dVVTlaNd+8eRMvvvgihg0b9qMNjIh+fB7dDz979myXudb3XZuj7Nu3r5hrPckfeughMdfmUCsq\nKsS8devWYq711S8qKhLz+Ph4Mc/NzRVzbR1E//79xRzQ5/I3bdok5toZ9c8++6yY19XVibnWM2D6\n9OliPn/+fDHXfkfbtGkj5t99952Yf/zxx2KelZXlMvvjH//I/fBEpmPBExmEBU9kEBY8kUFY8EQG\nYcETGYQFT2QQj54PL52PrfWF187W1vaLt2gh/79MW9d/5cqVJt1emyPW9pJr+9H//Oc/i7nWT0Dr\nF6BdX0Dv+67NU0dFRYn51atXxXzx4sViHh0dLebLly8Xc+0aBQYGinnnzp3FXFsn0KVLFzHn+fBE\nJGLBExmEBU9kEBY8kUFY8EQGYcETGYQFT2QQj87DS3uuO3XqJN42MTFRzE+fPi3m2n51bR5cO9u8\nQ4cOYq71TLfZbGL+/fffi3mPHj2adP8HDx4Uc+36AcCMGTPEfO3atWKu/Qx79uwRc39/fzF/8MEH\nxVxbq6GtM9D28yckJIi51ori4YcfFnOpp4Krnvx8hicyCAueyCAseCKDsOCJDMKCJzIIC57IICx4\nIoN4tC99w7Pl7nT8+HHx9tu2bRPzr7/+WswrKyvF/KWXXhLz7du3i/nPf/5zMS8pKRHzI0eOiHlG\nRoaYaz3htbPNtb782vgB/fzyM2fOiHlTexL06dNHzLX95lrPAm2eX1tHsG/fPjHv3bu3mC9dulTM\nBw4c6DKbNWsW+9ITmY4FT2QQFjyRQVjwRAZhwRMZhAVPZBAWPJFB1P3wU6ZMwcaNGxEQEODYQ11d\nXY3x48ejtLQU4eHhWL16NR599NG7biudsV5QUCA+rtbzW5sD1s43X7NmjZivWLFCzFeuXCnmMTEx\nYq7tp9d6sms9y7V59traWjHX5qgBfS2As9+Jhg4fPizmly5dEvOQkBAxLy8vF3PtGgcFBYm51rNA\nW2tx48YNMY+Pjxdz7XfAGfUZfvLkyXdtps/KykJKSgpOnDiBIUOGiAfTE5HvUAs+KSnprmfT9evX\nIz09HQCQnp6udjYhIt/g1t/wVVVVjpfcgYGBaisgIvINTe5pZ7PZXPZPy8zMdPx70KBBGDRoUFMf\njoicKCwsRGFhofp9bhV8YGAgKisrERQUhIqKCgQEBDj9voYFT0SeExcXh7i4OMfnH3/8sdPvc+sl\n/ahRo5CdnQ0AyM7OxpgxY9y5GyJqZmrBT5gwAf369cPx48cRFhaGv//975g7dy62bduGqKgofPHF\nF5g7d25zjJWImsij++H/9Kc/ucyrq6vF22t5mzZtxFybB2/VqpWYa3PM2l7sefPmifl3330n5kOH\nDhVz7T+b1IsAADp27CjmKSkpYg7oZwu8+eabYq7NQ3fr1k3MtT3/2vnurVu3FvPc3Fwx19aCaPvl\nS0tLxXzEiBFivnDhQpfZ2rVruR+eyHQseCKDsOCJDMKCJzIIC57IICx4IoOw4IkM4tHz4aW58K1b\nt4q37dy5s5jv2LHDrTHdpu3w086nP3v2rJhr89zaOoCWLVuK+a5du8T8iSeeEHNtL7i2lxsA5syZ\nI+ZFRUVirl2jL7/8Usy1tRhJSUlivnPnTjE/f/68mI8bN07MT506JeYRERFirq0FuXDhgpg7w2d4\nIoOw4IkMwoInMggLnsggLHgig7DgiQzCgicyiEf3w0tnnLtqi3Xb0aNHxVzbqzxp0iQx184m1/a7\n39m6+04bN24U865du4p5WFiYmGs91+vr68V88ODBYi6dKXCb1rx0wYIFYq71XR85cmSTHl/r/X/x\n4kUxb9euXZPu//Tp02KenJws5to8fk1Njcts2rRp3A9PZDoWPJFBWPBEBmHBExmEBU9kEBY8kUFY\n8EQG8eh++AcffNBldu7cOfG2Tz/9tJh3795dzFevXi3mv/zlL8VcOxtcm0fv3bu3mP/tb38T88cf\nf1zMtXl6Pz8/Mb9165aYf/jhh2IOACUlJWKelpYm5trvwNdffy3m2p5/7Xz6a9euibm21uE///mP\nmGsnMs2YMUPMY2NjxVzbL+8Mn+GJDMKCJzIIC57IICx4IoOw4IkMwoInMggLnsgg6jz8lClTsHHj\nRgQEBODgwYMAgMzMTCxdutSxH/jtt992Om9eW1vr8n6189vXrVsn5q+//rqYa3ulf/jhBzHfv3+/\nmEt7kQEgJydHzLV1AO3bt29Svn37djF/6KGHxHzChAliDgB79uxpUp6amirmWquGzz77TMzz8/PF\nPD09Xcy1ngAFBQVibrPZxPypp54S88jISDFv27atmDujPsNPnjz5rmYPNpsNr7zyCvLz85Gfn68u\nkiEi36AWfFJSEh577LG7vu6hRjlE5EFu/w2/aNEi2O12ZGRk4PLlyz/mmIjIQ9xaSz99+nTMmzcP\nAPDGG29g9uzZWLZs2V3f1/BvqKCgIAQHB7s5TCKSHD16VO0DCbhZ8A0bUE6dOhXPPfec0+9LSEhw\n5+6J6D5FR0cjOjra8bmrN43deklfUVHR6I61nWtE5BvUZ/gJEyZg165duHDhAsLCwjB//nzs3LkT\nBQUFsNlsiIiIwJIlS5pjrETURB7tS79t2zaX+apVq8Tba68aDh06JOZaT/G4uDgx185Hv3nzpphr\ne5WlXgGAvhdb65v/r3/9S8y1efzr16+LOaCfv67Nw2vXUPuT8NixY2Ku9Z1v1aqVmGs9CbS1Htpa\nE63v/j/+8Q8xl36+FStWsC89kelY8EQGYcETGYQFT2QQFjyRQVjwRAZhwRMZxKPz8HPnznWZR0VF\nibfXepLv27dPzEePHi3m2l5jbQ5Z6/uu7TfX5ohffPFFMdd6omt7sbWe8vfya6H9jIGBgWKu9SRo\n0UJ+PtLOZ6+vrxfzTz/9VMy1dQBaX/wuXbqI+SeffCLm2lqIAQMGuMwyMjI4D09kOhY8kUFY8EQG\nYcETGYQFT2QQFjyRQVjwRAbx6PnwpaWlLrOIiAjxttrZ2NoccMeOHcVc6pkP6D3Djx8/LuZaY88r\nV66I+YkTJ8Rcm6efNWuWmGvjO3PmjJgDwM9+9jMx79Spk5h/++23Yn7+/Hkx1+apb926JeZ9+/YV\nc+3sgd27d4u51nNA6yuvrQM4d+6cmDvDZ3gig7DgiQzCgicyCAueyCAseCKDsOCJDMKCJzKIR+fh\npb7e2jlYly5dEvNXX31VzD///HMxr6ysFPOrV6+KubZfXOs7/8wzz4h5bm6umGt7qbV1Di1bthRz\nV8eHNVRcXCzmRUVFYq71hdf29Gv73bW1GEOHDhVzreeCNs+u/Q5WV1eL+fDhw8VcOzvBGT7DExmE\nBU9kEBY8kUFY8EQGYcETGYQFT2QQFjyRQcS+9GVlZZg0aRLOnTsHm82GadOm4eWXX0Z1dTXGjx+P\n0tJShIeHY/Xq1Xj00Ucb37HNJs4l79+/XxyYtt9d2wusnR8/bdo0Mf/www/FXDs7XNsrPWLECDHX\neq5r96/1EwgKChLzNWvWiDkA/OEPfxBz7XxzbZ68rq5OzLWfQZunt9vtYj5//nwx79Wrl5hr58cH\nBASIudazQepHkJaWdv996f38/LBgwQIcPnwYX331FRYvXoyjR48iKysLKSkpOHHiBIYMGYKsrCxx\nYETkG8SCDwoKQnx8PADA398f0dHRKC8vx/r165Geng4ASE9Px9q1az0/UiJqsnv+G76kpAT5+fno\n06cPqqqqHMcIBQYGqi9diMg33NNa+pqaGqSmpmLhwoV39eGy2Wwu1zwvX77c8e+EhAS1RxcRuefo\n0aPq/hTgHgq+vr4eqampSEtLw5gxYwD877N6ZWUlgoKCUFFR4fLNhylTptznsInIHdHR0YiOjnZ8\nnpOT4/T7xJf0lmUhIyMDMTExmDlzpuPro0aNQnZ2NgAgOzvb8T8CIvJt4jN8Xl4eVqxYgbi4OMfL\n8bfffhtz587FL37xCyxbtswxLUdEvs+j58NPnDjRZa7t19bm2Xft2iXmkydPFnNtHv3ChQti/uWX\nX4q5NoeqnY0+depUMdfmcLdu3Srmp0+fFvNf//rXYg7o89DaPLy2nzwxMVHMtf3mWk8Dba3Cww8/\nLObaPL92tsCOHTvEfNy4cWLeunVrl9mkSZN4PjyR6VjwRAZhwRMZhAVPZBAWPJFBWPBEBmHBExnE\no33ppf3K2tni27dvF/OUlBQx184W7969u5hfvHhRzFNTU8X8/fffF/PIyEgxP3nypJiXlpaKebt2\n7cRcm4MuKSkRcwA4duyYmGt96d99910x19Ya/Pa3vxXzwsJCMdfOr2/Tpo2Y9+nTR8y1tRja76C2\nVuWf//ynmDvDZ3gig7DgiQzCgicyCAueyCAseCKDsOCJDMKCJzKIR+fha2pqXGba2dvaHKzWt147\nO/vOPvr3Sztf/aWXXhLzvLw8MdfmiLWf/+DBg2KelJQk5to6AEBfq1BZWSnmQ4YMEfNXXnlFzD/6\n6CMx19Z6aPP0Tz75pJhrayHOnj0r5v7+/mKu/Q5r6wSc4TM8kUFY8EQGYcETGYQFT2QQFjyRQVjw\nRAZhwRMZxKN96efOnesy1/qya3OU2tni2l5hrSe6dv/SGgMACAkJEfNHHnlEzK9cuSLmrs7zuy0u\nLk7Mtb3sWk94ADhw4ICYjxgxQsy1efgFCxaI+ZkzZ8S8S5cuYv673/1OzBcvXizm2llu2u/Ahg0b\nxPynP/2pmCcnJ7vMBg4cyL70RKZjwRMZhAVPZBAWPJFBWPBEBmHBExlELPiysjIMHjwY3bp1Q2xs\nLN577z0AQGZmJkJDQ5GQkICEhARs2bKlWQZLRE0jzsNXVlaisrIS8fHxqKmpQc+ePbF27VqsXr0a\nbdu2Ffcr22w28X8EVVVV4sC0XDvfXTo7GwA+/fRTMR82bJiY19XViXlYWJiYa3O4HTp0EPOePXuK\n+ZIlS8RcW4eg9c0H9LMDtMfQrpG2H1zr667dvn///mKu7cefN2+emH///fdifv36dTEPDg4W8169\nernM+vXr53QeXmyAERQU5DhMwt/fH9HR0SgvLwcAp3dGRL7tnv+GLykpQX5+Pvr27QsAWLRoEex2\nOzIyMnD58mWPDZCIfjz3VPA1NTV4/vnnsXDhQvj7+2P69OkoLi5GQUEBgoODMXv2bE+Pk4h+BGpP\nu/r6eqSmpmLixIkYM2YMgMb95qZOnYrnnnvO6W0b9hyLi4uD3W5v6niJyIn9+/dj//796veJBW9Z\nFjIyMhATE4OZM2c6vl5RUeF4QyEnJ8flmydpaWn3M2YiclOPHj3Qo0cPx+fLly93+n1iwefl5WHF\nihWIi4tDQkICAOCtt97CypUrUVBQAJvNhoiICPUdYSLyDWLBDxgwwOk21meeecZjAyIiz/FoX/r8\n/HyXWVRUlHjbPXv2iLk2Ldi7d28xb/jyxxltHlybRz9x4oSYf/PNN2IeExMj5lq/AG382l7r8+fP\nizkAjBw5Usyrq6vFXJtn3rt3r5hrayG0vvmffPKJmKenp4u51tNg06ZNYl5UVCTm2oK2nJwcMXeG\nS2uJDMKCJzIIC57IICx4IoOw4IkMwoInMggLnsggHp2Hl+bStb3A0l5fAFi2bJmYa+enV1RUiPnt\nbcGunDp1Ssy1vvXa+e+HDh0S87KyMjHX5ri18+O1nu+APldfW1sr5tp+8YiICDHXevPPmDFDzLUF\nZL/5zW/EvL6+Xsy1ngIDBw4U8zfffFPMAwMDxdwZPsMTGYQFT2QQFjyRQZqt4LV1zd52u3WXr/L1\n63cvf/N7k3YOnrdp7wn9WFjw/+fs2bPeHoJI24jibb5e8IWFhd4egui/ruCJyPtY8EQmsTwkOTnZ\nAsAPfvDDCx/JyclO61I8iIKI/rvwJT2RQVjwRAZhwRMZhAVPZBAWPJFB/gcBixUMY04NyAAAAABJ\nRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x837a080>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "example:  4 / 4\n",
        "fitting the model...\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1000 iterations done\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD7CAYAAABOrvnfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMKCJzIIC57IIP8DSiccDh1joCwAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x5645668>"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We tested our algorithm in four example images but the results are not correct. This is due to some malfunction in our code which didn't have the time to find."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}